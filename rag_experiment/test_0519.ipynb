{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac101712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import re\n",
    "import pathlib\n",
    "\n",
    "class ChromaVectorDB:\n",
    "    \"\"\"ChromaDB를 이용한 벡터 DB 관리 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model, persist_directory=\"./chroma_db\", collection_name=\"Gray\"):\n",
    "        \"\"\"\n",
    "        ChromaDB 초기화\n",
    "        \n",
    "        Args:\n",
    "            embedding_model: 임베딩 모델 (SentenceTransformer 또는 호환 래퍼)\n",
    "            persist_directory (str): 벡터 DB가 저장될 디렉토리 경로\n",
    "            collection_name (str): 컬렉션 이름\n",
    "        \"\"\"\n",
    "        # 디렉토리 생성 확인\n",
    "        os.makedirs(persist_directory, exist_ok=True)\n",
    "        \n",
    "        # 임베딩 모델 저장\n",
    "        self.embedding_model = embedding_model\n",
    "        \n",
    "        # 기존 데이터베이스 디렉토리 확인 및 처리\n",
    "        db_path = pathlib.Path(persist_directory)\n",
    "        db_exists = db_path.exists() and any(db_path.iterdir())\n",
    "        \n",
    "        # 사용자 정의 임베딩 함수 생성 - 기존 embedding_model을 활용\n",
    "        self.embedding_function = CustomEmbeddingFunction(self.embedding_model)\n",
    "        \n",
    "        # 만약 데이터베이스가 손상되었거나 호환성 문제가 있다면 다시 생성\n",
    "        try:\n",
    "            self.client = chromadb.PersistentClient(path=persist_directory)\n",
    "            \n",
    "            # 컬렉션 가져오기\n",
    "            try:\n",
    "                self.collection = self.client.get_collection(\n",
    "                    name=collection_name,\n",
    "                    embedding_function=self.embedding_function\n",
    "                )\n",
    "                print(f\"기존 컬렉션 '{collection_name}'을 로드했습니다.\")\n",
    "            except Exception as e:\n",
    "                print(f\"컬렉션 로드 중 오류 발생: {e}\")\n",
    "                \n",
    "                # 오류가 'max_seq_id' 관련 문제인지 확인\n",
    "                if \"max_seq_id\" in str(e) or \"PersistentData\" in str(e):\n",
    "                    print(\"데이터베이스 구조 호환성 문제가 발견되었습니다. 컬렉션을 재생성합니다.\")\n",
    "                    \n",
    "                    # 기존 컬렉션 제거 시도\n",
    "                    try:\n",
    "                        self.client.delete_collection(name=collection_name)\n",
    "                        print(f\"기존 컬렉션 '{collection_name}'을 삭제했습니다.\")\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 새 컬렉션 생성\n",
    "                    self.collection = self.client.create_collection(\n",
    "                        name=collection_name,\n",
    "                        embedding_function=self.embedding_function\n",
    "                    )\n",
    "                    print(f\"새 컬렉션 '{collection_name}'을 생성했습니다.\")\n",
    "                else:\n",
    "                    # 다른 종류의 오류면 새 컬렉션 생성\n",
    "                    print(f\"새 컬렉션 '{collection_name}'을 생성합니다.\")\n",
    "                    self.collection = self.client.create_collection(\n",
    "                        name=collection_name,\n",
    "                        embedding_function=self.embedding_function\n",
    "                    )\n",
    "                    \n",
    "        except Exception as outer_e:\n",
    "            print(f\"치명적 오류: ChromaDB 클라이언트 초기화 실패: {outer_e}\")\n",
    "            print(\"백업 솔루션: 기존 데이터베이스를 재설정합니다.\")\n",
    "            \n",
    "            # 데이터베이스 디렉토리가 존재하면 백업 후 재생성\n",
    "            if db_exists:\n",
    "                # 기존 폴더 백업 (이름 변경)\n",
    "                import shutil\n",
    "                import time\n",
    "                \n",
    "                backup_dir = f\"{persist_directory}_backup_{int(time.time())}\"\n",
    "                try:\n",
    "                    shutil.move(persist_directory, backup_dir)\n",
    "                    print(f\"기존 데이터베이스를 {backup_dir}로 백업했습니다.\")\n",
    "                except Exception as move_err:\n",
    "                    print(f\"백업 실패: {move_err}\")\n",
    "                    # 기존 폴더 삭제 시도\n",
    "                    try:\n",
    "                        shutil.rmtree(persist_directory)\n",
    "                        print(f\"기존 데이터베이스 폴더를 삭제했습니다.\")\n",
    "                    except Exception as rm_err:\n",
    "                        print(f\"폴더 삭제 실패: {rm_err}\")\n",
    "            \n",
    "            # 폴더 재생성\n",
    "            os.makedirs(persist_directory, exist_ok=True)\n",
    "            \n",
    "            # 클라이언트와 컬렉션 새로 생성\n",
    "            self.client = chromadb.PersistentClient(path=persist_directory)\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=collection_name,\n",
    "                embedding_function=self.embedding_function\n",
    "            )\n",
    "            print(f\"ChromaDB를 재설정하고 새 컬렉션 '{collection_name}'을 생성했습니다.\")\n",
    "    \n",
    "    def change_collection(self, collection_name):\n",
    "        \"\"\"컬렉션 변경\"\"\"\n",
    "        try:\n",
    "            self.collection = self.client.get_collection(name=collection_name)\n",
    "            self.collection_name = collection_name\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"컬렉션 변경 실패: {e}\")\n",
    "            return False\n",
    "        \n",
    "    def search_with_embedding(self, embedding, top_n=5):\n",
    "        \"\"\"\n",
    "        임베딩 벡터를 사용하여 검색\n",
    "        \n",
    "        Args:\n",
    "            embedding (list): 쿼리 임베딩 벡터\n",
    "            top_n (int): 반환할 결과 수\n",
    "            metadata_filter (dict, optional): 메타데이터 필터링 조건\n",
    "        \n",
    "        Returns:\n",
    "            dict: 검색 결과\n",
    "        \"\"\"\n",
    "        try :\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=[embedding],\n",
    "                n_results=top_n,\n",
    "                include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "            )\n",
    "            \n",
    "            # 결과 포맷팅\n",
    "            formatted_results = []\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                for i, (doc, metadata, distance) in enumerate(zip(\n",
    "                    results['documents'][0], \n",
    "                    results['metadatas'][0], \n",
    "                    results['distances'][0]\n",
    "                )):\n",
    "                    formatted_results.append({\n",
    "                        'id': results['ids'][0][i] if 'ids' in results else f\"doc_{i}\",\n",
    "                        'document': doc,\n",
    "                        'chunk': doc,\n",
    "                        'distance': distance,\n",
    "                        'page': metadata.get('page', 1) if metadata else 1,\n",
    "                        'index': i\n",
    "                    })\n",
    "            \n",
    "            return formatted_results\n",
    "        except Exception as e:\n",
    "            print(f\"임베딩 검색 실패: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def add_documents(self, documents, metadatas=None, ids=None):\n",
    "        \"\"\"\n",
    "        문서를 벡터 DB에 추가\n",
    "        \n",
    "        Args:\n",
    "            documents (list): 문서 텍스트 리스트\n",
    "            metadatas (list, optional): 각 문서에 대한 메타데이터 리스트\n",
    "            ids (list, optional): 각 문서에 대한 고유 ID 리스트\n",
    "        \n",
    "        Returns:\n",
    "            int: 추가된 문서 수\n",
    "        \"\"\"\n",
    "        if ids is None:\n",
    "            # 고유한 ID 생성 (timestamp + index)\n",
    "            import time\n",
    "            timestamp = int(time.time())\n",
    "            ids = [f\"doc_{timestamp}_{i}\" for i in range(len(documents))]\n",
    "        \n",
    "        # 메타데이터가 제공되지 않은 경우 빈 딕셔너리 생성\n",
    "        if metadatas is None:\n",
    "            metadatas = [{} for _ in range(len(documents))]\n",
    "        \n",
    "        # 문서 임베딩 미리 계산 - 디버깅 용도\n",
    "        # embeddings = self.embedding_model.encode(documents)\n",
    "        \n",
    "        # 문서 추가 (임베딩은 임베딩 함수가 자동 계산)\n",
    "        self.collection.add(\n",
    "            documents=documents,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )\n",
    "        \n",
    "        return len(documents)\n",
    "    \n",
    "    def load_document_file(self, file_path, chunk_size=None):\n",
    "        \"\"\"\n",
    "        파일을 로드하여 벡터 DB에 저장\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): 로드할 파일 경로\n",
    "            chunk_size (int, optional): 청크 분할 크기 (None이면 페이지 단위로 분할)\n",
    "            \n",
    "        Returns:\n",
    "            int: 추가된 청크 수\n",
    "        \"\"\"\n",
    "        # 파일 확장자 확인\n",
    "        # _, ext = os.path.splitext(file_path)\n",
    "        \n",
    "        # 파일 읽기\n",
    "        try:\n",
    "            print(f\"파일 로드 중: {file_path}\")\n",
    "            text_content = pathlib.Path(file_path).read_text(encoding=\"utf-8\")\n",
    "            print(f\"파일 크기: {len(text_content)} 문자\")\n",
    "        except Exception as e:\n",
    "            print(f\"파일 로드 오류: {e}\")\n",
    "            return 0\n",
    "        \n",
    "        # 청크 분할 방식 결정\n",
    "        chunks = []\n",
    "        metadatas = []\n",
    "        \n",
    "        if chunk_size:\n",
    "            # 지정된 청크 크기로 분할\n",
    "            current_pos = 0\n",
    "            while current_pos < len(text_content):\n",
    "                chunk = text_content[current_pos:current_pos + chunk_size]\n",
    "                chunks.append(chunk)\n",
    "                metadatas.append({\"source\": file_path, \"chunk_index\": len(chunks)})\n",
    "                current_pos += chunk_size\n",
    "            \n",
    "            print(f\"크기 기반 분할: {len(chunks)}개 청크 생성\")\n",
    "        else:\n",
    "            # 페이지 단위 분할 (#### Page X 패턴 사용)\n",
    "            page_pattern = r'(####\\s+Page\\s+\\d+\\s*\\n(?:[\\s\\S]*?)(?=####\\s+Page\\s+\\d+\\s*\\n|$))'\n",
    "            page_chunks = re.findall(page_pattern, text_content)\n",
    "            \n",
    "            if page_chunks:\n",
    "                # 페이지 패턴 찾음\n",
    "                for page_chunk in page_chunks:\n",
    "                    # 페이지 번호 추출\n",
    "                    page_match = re.match(r'####\\s+Page\\s+(\\d+)', page_chunk)\n",
    "                    page_num = page_match.group(1) if page_match else \"unknown\"\n",
    "                    \n",
    "                    chunks.append(page_chunk)\n",
    "                    metadatas.append({\"source\": file_path, \"page\": f\"Page {page_num}\"})\n",
    "                \n",
    "                print(f\"페이지 기반 분할: {len(chunks)}개 페이지 찾음\")\n",
    "            else:\n",
    "                # 페이지 패턴 못찾음 - 문단 단위로 분할\n",
    "                paragraphs = re.split(r'\\n\\s*\\n', text_content)\n",
    "                paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "                \n",
    "                for i, para in enumerate(paragraphs):\n",
    "                    chunks.append(para)\n",
    "                    metadatas.append({\"source\": file_path, \"paragraph\": i+1})\n",
    "                \n",
    "                print(f\"문단 기반 분할: {len(chunks)}개 문단 생성\")\n",
    "        \n",
    "        # 청크가 없으면 전체 텍스트를 하나의 청크로 처리\n",
    "        if not chunks:\n",
    "            chunks = [text_content]\n",
    "            metadatas = [{\"source\": file_path, \"full_document\": True}]\n",
    "            print(\"분할 실패: 전체 텍스트를 하나의 청크로 처리\")\n",
    "        \n",
    "        # 벡터 DB에 추가\n",
    "        added_count = self.add_documents(\n",
    "            documents=chunks,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        \n",
    "        print(f\"벡터 DB에 {added_count}개 청크 추가 완료\")\n",
    "        return added_count\n",
    "    \n",
    "    # def search(self, query=None, query_embeddings=None, top_n=5, metadata_filter=None):\n",
    "    #     \"\"\"\n",
    "    #     벡터 유사도 기반 검색 수행\n",
    "        \n",
    "    #     Args:\n",
    "    #         query (str, optional): 텍스트 검색 쿼리 (query_embeddings이 제공되지 않을 때 사용)\n",
    "    #         query_embeddings (list, optional): 직접 제공하는 쿼리 임베딩 리스트\n",
    "    #         top_n (int): 반환할 결과 수\n",
    "    #         metadata_filter (dict, optional): 메타데이터 필터링 조건\n",
    "        \n",
    "    #     Returns:\n",
    "    #         dict: 검색 결과\n",
    "    #     \"\"\"\n",
    "    #     # 쿼리 임베딩 처리\n",
    "    #     if query_embeddings is None and query is not None:\n",
    "    #         query_embedding = self.embedding_model.encode([query])[0]\n",
    "    #         query_embeddings = [query_embedding.tolist()]\n",
    "    #         print(f\"쿼리 임베딩 shape: {query_embedding.shape}\")\n",
    "        \n",
    "    #     # ChromaDB를 통한 검색\n",
    "    #     results = self.collection.query(\n",
    "    #         query_embeddings=query_embeddings,  # query_texts 대신 query_embeddings 사용\n",
    "    #         n_results=top_n,\n",
    "    #         where=metadata_filter,\n",
    "    #         include=[\"documents\", \"metadatas\", \"distances\", \"embeddings\"]\n",
    "    #     )\n",
    "        \n",
    "    #     # 결과 포맷팅\n",
    "    #     formatted_results = []\n",
    "    #     for i in range(len(results[\"documents\"][0])):\n",
    "    #         formatted_results.append({\n",
    "    #             \"chunk\": results[\"documents\"][0][i],\n",
    "    #             \"id\": results[\"ids\"][0][i],\n",
    "    #             \"metadata\": results[\"metadatas\"][0][i],\n",
    "    #             \"distance\": results[\"distances\"][0][i] if \"distances\" in results else None,\n",
    "    #             # \"embedding\": results[\"embeddings\"][0][i] if \"embeddings\" in results else None\n",
    "    #         })\n",
    "        \n",
    "    #     return formatted_results\n",
    "\n",
    "    # def search(self, query, top_n=5, metadata_filter=None):\n",
    "    #     \"\"\"\n",
    "    #     벡터 유사도 기반 검색 수행\n",
    "        \n",
    "    #     Args:\n",
    "    #         query (str): 검색 쿼리\n",
    "    #         top_n (int): 반환할 결과 수\n",
    "    #         metadata_filter (dict, optional): 메타데이터 필터링 조건\n",
    "        \n",
    "    #     Returns:\n",
    "    #         dict: 검색 결과\n",
    "    #     \"\"\"\n",
    "    #     # 진단용 - 쿼리 임베딩 계산\n",
    "    #     query_embedding = self.embedding_model.encode([query])[0]\n",
    "    #     print(f\"쿼리 임베딩 shape: {query_embedding.shape}\")\n",
    "        \n",
    "    #     # ChromaDB를 통한 검색\n",
    "    #     results = self.collection.query(\n",
    "    #         query_texts=[query],\n",
    "    #         n_results=top_n,\n",
    "    #         where=metadata_filter,\n",
    "    #         include=[\"documents\", \"metadatas\", \"distances\", \"embeddings\"]\n",
    "    #     )\n",
    "        \n",
    "    #     # 결과 포맷팅\n",
    "    #     formatted_results = []\n",
    "    #     for i in range(len(results[\"documents\"][0])):\n",
    "    #         formatted_results.append({\n",
    "    #             \"chunk\": results[\"documents\"][0][i],\n",
    "    #             \"id\": results[\"ids\"][0][i],\n",
    "    #             \"metadata\": results[\"metadatas\"][0][i],\n",
    "    #             \"distance\": results[\"distances\"][0][i] if \"distances\" in results else None,\n",
    "    #             # \"embedding\": results[\"embeddings\"][0][i] if \"embeddings\" in results else None\n",
    "    #         })\n",
    "        \n",
    "    #     return formatted_results\n",
    "    \n",
    "    # def get_all_document_embeddings(self, ids=None):\n",
    "    #     \"\"\"\n",
    "    #     저장된 모든 문서의 임베딩 조회 (디버깅 용도)\n",
    "    #     \"\"\"\n",
    "    #     result = self.collection.get(ids=ids, include=[\"embeddings\", \"documents\"])\n",
    "    #     return result\n",
    "    \n",
    "    # def get_document_by_id(self, doc_id):\n",
    "    #     \"\"\"ID로 문서 조회\"\"\"\n",
    "    #     result = self.collection.get(ids=[doc_id])\n",
    "    #     if result[\"documents\"]:\n",
    "    #         return {\n",
    "    #             \"chunk\": result[\"documents\"][0],\n",
    "    #             \"metadata\": result[\"metadatas\"][0]\n",
    "    #         }\n",
    "    #     return None\n",
    "    \n",
    "    # def delete_document(self, doc_id):\n",
    "    #     \"\"\"ID로 문서 삭제\"\"\"\n",
    "    #     self.collection.delete(ids=[doc_id])\n",
    "    \n",
    "    def delete_collection(self):\n",
    "        \"\"\"컬렉션 삭제\"\"\"\n",
    "        self.client.delete_collection(self.collection.name)\n",
    "    \n",
    "    def get_collection_stats(self):\n",
    "        \"\"\"컬렉션 통계 조회\"\"\"\n",
    "        count = self.collection.count()\n",
    "        return {\n",
    "            \"document_count\": count,\n",
    "            \"collection_name\": self.collection.name\n",
    "        }\n",
    "    \n",
    "class CustomEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    \"\"\"기존 임베딩 모델을 ChromaDB에서 사용하기 위한 래퍼 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        \n",
    "        Args:\n",
    "            embedding_model: 임베딩 모델 (encode 메서드 제공)\n",
    "        \"\"\"\n",
    "        self.embedding_model = embedding_model\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        \"\"\"\n",
    "        텍스트를 임베딩 벡터로 변환\n",
    "        \n",
    "        Args:\n",
    "            texts: 인코딩할 텍스트 리스트\n",
    "        \n",
    "        Returns:\n",
    "            임베딩 벡터 리스트\n",
    "        \"\"\"\n",
    "        return self.embedding_model.encode(texts).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df0ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from model_loader.config import embedding_loader, generation_loader\n",
    "\n",
    "class HybridSearcher:\n",
    "    def __init__(self, embedding_model, chunk_size=200, chunk_overlap=50, \n",
    "                 persist_directory=\"./chroma_db\", collection_name=\"Gray\"):\n",
    "        \"\"\"\n",
    "        하이브리드 검색 클래스 초기화\n",
    "        \n",
    "        Args:\n",
    "            embedding_model: 임베딩 모델\n",
    "            chunk_size (int): 청크 크기\n",
    "            chunk_overlap (int): 청크 간 중복 크기\n",
    "            persist_directory (str): 벡터 DB 저장 경로\n",
    "            collection_name (str): 벡터 DB 컬렉션 이름\n",
    "        \"\"\"\n",
    "        self.embedding_model = embedding_model\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.collection_name = collection_name\n",
    "        self.chunks = None\n",
    "        self.chunk_metadata = None\n",
    "        self.bm25_index = None\n",
    "        self.vector_index = None\n",
    "        self.persist_directory=persist_directory\n",
    "        \n",
    "        # ChromaDB 벡터 DB 클래스 초기화 - 동일한 임베딩 모델 사용\n",
    "        self.vector_db = ChromaVectorDB(\n",
    "            embedding_model=self.embedding_model,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "        \n",
    "        # 검색 결과 비교용 플래그\n",
    "        self.debug_mode = False\n",
    "        \n",
    "        # 프롬프트 로드\n",
    "        self.complexity_prompt = self._load_prompt(\"prompts/en/complex/complex_prompt.txt\")\n",
    "        self.decompose_prompt = self._load_prompt(\"prompts/en/decompose/decompose_prompt.txt\")\n",
    "\n",
    "    def _load_prompt(self, file_path):\n",
    "        \"\"\"프롬프트 파일 로드\"\"\"\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"프롬프트 파일 로드 중 오류 발생: {e}\")\n",
    "            # 기본 프롬프트 반환\n",
    "            if \"complex\" in file_path:\n",
    "                return \"질문을 분석하여 복합적인 질문인지 판단하세요. 복합적인 질문은 여러 하위 질문으로 분해할 수 있습니다. '예' 또는 '아니오'로만 답변하세요.\"\n",
    "            elif \"decompose\" in file_path:\n",
    "                return \"다음 복합적인 질문을 여러 개의 간단한 하위 질문으로 분해하세요. JSON 형식으로 하위 질문 목록을 반환하세요.\"\n",
    "\n",
    "    def multi_collection_search(self, query, top_n_per_collection=5, final_top_n=5, alpha=0.5):\n",
    "        \"\"\"\n",
    "        여러 컬렉션에서 검색하여 최종 상위 결과 반환\n",
    "        \n",
    "        Args:\n",
    "            query (str): 검색 쿼리\n",
    "            top_n_per_collection (int): 각 컬렉션에서 가져올 결과 수\n",
    "            final_top_n (int): 최종 반환할 결과 수\n",
    "            alpha (float): BM25와 벡터 검색 결합 비율\n",
    "        \n",
    "        Returns:\n",
    "            list: 최종 검색 결과 리스트\n",
    "        \"\"\"\n",
    "        collections = [\"1_Embryology\", \"2_Osteology\", \"3_Syndesmology\", \"4_Myology\", \n",
    "                    \"5_Angiology\", \"6_The_Arteries\", \"7_The_Veins\", \"8_The_Lymphatic_System\", \n",
    "                    \"9_Neurology\", \"10_The_Organs_of_the_Senses_and_the_Common_Integument\", \n",
    "                    \"11_Splanchnology\", \"12_Surface_Anatomy_and_Surface_Markings\"]\n",
    "        \n",
    "        all_results = []\n",
    "        original_collection = getattr(self.vector_db, 'collection_name', None)\n",
    "        \n",
    "        # 쿼리 임베딩 생성 (한 번만)\n",
    "        if not isinstance(query, str):\n",
    "            query = str(query)\n",
    "        \n",
    "        # 구두점으로 쿼리 분할하여 평균 임베딩 생성\n",
    "        query_parts = re.split(r'[.!?;]', query)\n",
    "        query_parts = [part.strip() for part in query_parts if part.strip()]\n",
    "        \n",
    "        if query_parts:\n",
    "            part_embeddings = self.embedding_model.encode(query_parts)\n",
    "            query_embedding = np.mean(part_embeddings, axis=0)\n",
    "        else:\n",
    "            query_embedding = self.embedding_model.encode([query])[0]\n",
    "        \n",
    "        # 각 컬렉션에서 검색\n",
    "        for collection_name in collections:\n",
    "            try:\n",
    "                # 컬렉션 변경\n",
    "                self.vector_db.change_collection(collection_name)\n",
    "                \n",
    "                # 해당 컬렉션에서 검색\n",
    "                db_results = self.vector_db.search_with_embedding(\n",
    "                    embedding=query_embedding.tolist(), \n",
    "                    top_n=top_n_per_collection\n",
    "                )\n",
    "                \n",
    "                # 결과에 컬렉션 정보 추가\n",
    "                for result in db_results:\n",
    "                    result['collection'] = collection_name\n",
    "                    result['combined_score'] = 1.0 - result['distance']  # 거리를 유사도로 변환\n",
    "                    all_results.append(result)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"컬렉션 {collection_name} 검색 중 오류: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 원래 컬렉션으로 복원\n",
    "        if original_collection:\n",
    "            try:\n",
    "                self.vector_db.change_collection(original_collection)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # 점수 기준으로 정렬하여 상위 결과 반환\n",
    "        all_results.sort(key=lambda x: x['combined_score'], reverse=True)\n",
    "        final_results = all_results[:final_top_n]\n",
    "        \n",
    "        # 기존 형식에 맞게 변환\n",
    "        formatted_results = []\n",
    "        for result in final_results:\n",
    "            formatted_results.append({\n",
    "                \"chunk\": result.get('chunk', result.get('document', '')),\n",
    "                \"score\": result['combined_score'],\n",
    "                \"bm25_score\": 0.0,  # 벡터 검색만 사용\n",
    "                \"vector_score\": result['combined_score'],\n",
    "                \"memory_score\": result['combined_score'],\n",
    "                \"index\": result.get('index', 0),\n",
    "                \"page\": result.get('page', 1),\n",
    "                \"collection\": result['collection']\n",
    "            })\n",
    "        \n",
    "        return formatted_results\n",
    "    \n",
    "    def load_document(self, file_path):\n",
    "        \"\"\"문서 로드 및 청크 분할\"\"\"\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # 문서를 청크로 분할\n",
    "        self.chunks, self.chunk_metadata = self._split_into_chunks_with_metadata(content)\n",
    "        \n",
    "        # BM25 인덱스 생성\n",
    "        tokenized_chunks = [self._simple_tokenize(chunk) for chunk in self.chunks]\n",
    "        self.bm25_index = BM25Okapi(tokenized_chunks)\n",
    "        \n",
    "        # 벡터 임베딩 생성 및 인메모리 인덱스 구축\n",
    "        self.vector_index = self.embedding_model.encode(self.chunks)\n",
    "        \n",
    "        # ChromaDB에 문서 추가\n",
    "        # 문서 ID 생성\n",
    "        doc_name = os.path.basename(file_path)\n",
    "        doc_ids = [f\"{doc_name}_{i}\" for i in range(len(self.chunks))]\n",
    "        \n",
    "        # 메타데이터에 페이지 정보 포함\n",
    "        metadatas = [{\"page\": meta[\"page\"], \"source\": doc_name, \"chunk_index\": i} \n",
    "                    for i, meta in enumerate(self.chunk_metadata)]\n",
    "        \n",
    "        # 벡터 DB에 문서 추가\n",
    "        self.vector_db.add_documents(\n",
    "            documents=self.chunks,\n",
    "            metadatas=metadatas,\n",
    "            ids=doc_ids\n",
    "        )\n",
    "        \n",
    "        return len(self.chunks)\n",
    "    \n",
    "    def search(self, query, top_n=5, alpha=0.5, use_vector_db=True):\n",
    "        \"\"\"\n",
    "        하이브리드 검색 수행\n",
    "        \n",
    "        Args:\n",
    "            query (str): 검색 쿼리\n",
    "            top_n (int): 반환할 결과 수\n",
    "            alpha (float): BM25와 벡터 검색 결과 결합 비율 (0에 가까울수록 벡터 검색 중시)\n",
    "            use_vector_db (bool): ChromaDB 벡터 DB 사용 여부\n",
    "        \n",
    "        Returns:\n",
    "            list: 검색 결과 리스트\n",
    "        \"\"\"\n",
    "        if self.chunks is None or self.bm25_index is None:\n",
    "            raise ValueError(\"문서가 로드되지 않았습니다. load_document()를 먼저 호출하세요.\")\n",
    "        \n",
    "        if not isinstance(query, str) :\n",
    "            query = str(query)\n",
    "            \n",
    "        # BM25 검색 수행\n",
    "        bm25_scores = self.bm25_index.get_scores(self._simple_tokenize(query))\n",
    "        \n",
    "        # 두 검색 방식 모두 수행 (디버그 모드)\n",
    "        query_embedding = self.embedding_model.encode([query])[0]\n",
    "        memory_scores = cosine_similarity([query_embedding], self.vector_index)[0]\n",
    "        \n",
    "        if use_vector_db:\n",
    "            # ChromaDB를 사용한 벡터 검색\n",
    "            # db_results = self.vector_db.search(query, top_n=len(self.chunks))\n",
    "            db_results = self.vector_db.search_with_embedding(\n",
    "                embedding=query_embedding.tolist(), \n",
    "                top_n=len(self.chunks)\n",
    "            )\n",
    "            # 결과를 벡터 점수로 변환\n",
    "            vector_scores = np.zeros(len(self.chunks))\n",
    "            for res in db_results:\n",
    "                # 문서 ID에서 인덱스 추출\n",
    "                chunk_id = res[\"id\"]\n",
    "                if \"_\" in chunk_id:\n",
    "                    try:\n",
    "                        chunk_index = int(chunk_id.split(\"_\")[-1])\n",
    "                        if chunk_index < len(self.chunks):\n",
    "                            # 거리를 유사도로 변환 (코사인 거리는 1 - 코사인 유사도)\n",
    "                            if res[\"distance\"] is not None:\n",
    "                                # ChromaDB가 코사인 거리를 사용하는 경우\n",
    "                                similarity = 1.0 - res[\"distance\"]\n",
    "                                vector_scores[chunk_index] = similarity\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            \n",
    "            # 디버그 모드에서 점수 비교\n",
    "            if self.debug_mode:\n",
    "                print(\"\\n벡터 검색 점수 비교:\")\n",
    "                for i in range(min(5, len(self.chunks))):\n",
    "                    print(f\"Chunk {i}: Memory={memory_scores[i]:.4f}, ChromaDB={vector_scores[i]:.4f}, 차이={memory_scores[i]-vector_scores[i]:.4f}\")\n",
    "        else:\n",
    "            # 메모리 내 벡터 검색 수행 (기존 방식)\n",
    "            vector_scores = memory_scores\n",
    "        \n",
    "        # 검색 결과 결합\n",
    "        combined_scores = self._combine_scores(bm25_scores, vector_scores, alpha)\n",
    "        \n",
    "        # 상위 N개 결과 반환\n",
    "        top_indices = np.argsort(combined_scores)[-top_n:][::-1]\n",
    "        results = [\n",
    "            {\n",
    "                \"chunk\": self.chunks[i],\n",
    "                \"score\": combined_scores[i],\n",
    "                \"bm25_score\": bm25_scores[i],\n",
    "                \"vector_score\": vector_scores[i],\n",
    "                \"memory_score\": memory_scores[i],  # 디버깅용\n",
    "                \"index\": i,\n",
    "                \"page\": self.chunk_metadata[i][\"page\"]\n",
    "            }\n",
    "            for i in top_indices\n",
    "        ]\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def multi_sentence_hybrid_search(self, query, top_n=5, similarity_threshold=0.7, alpha=0.5, use_vector_db=True):\n",
    "        \"\"\"\n",
    "        가상 문서를 문장 단위로 분할하여 각 문장으로 하이브리드 검색 수행 후 결과 병합\n",
    "        \n",
    "        Args:\n",
    "            query (str): 검색 쿼리\n",
    "            top_n (int): 반환할 결과 수\n",
    "            similarity_threshold (float): 하이브리드 점수 임계값 (이 값 이상인 결과만 포함)\n",
    "            alpha (float): BM25와 벡터 검색 결과 결합 비율 (0에 가까울수록 벡터 검색 중시)\n",
    "            use_vector_db (bool): ChromaDB 벡터 DB 사용 여부\n",
    "        \n",
    "        Returns:\n",
    "            list: 검색 결과 리스트\n",
    "        \"\"\"\n",
    "        if self.chunks is None or self.bm25_index is None:\n",
    "            raise ValueError(\"문서가 로드되지 않았습니다. load_document()를 먼저 호출하세요.\")\n",
    "        \n",
    "        if not isinstance(query, str):\n",
    "            query = str(query)\n",
    "        \n",
    "        # 구두점으로 쿼리 분할\n",
    "        query_parts = re.split(r'[.!?;]', query)\n",
    "        query_parts = [part.strip() for part in query_parts if part.strip()]\n",
    "        \n",
    "        if not query_parts:\n",
    "            # 분할 결과가 없으면 기존 mean_search 사용\n",
    "            return self.mean_search(query, top_n, alpha=alpha, use_vector_db=use_vector_db)\n",
    "        \n",
    "        # 각 문장별 검색 결과를 저장할 리스트\n",
    "        all_results = []\n",
    "        \n",
    "        # 각 문장에 대해 검색 수행\n",
    "        for part in query_parts:\n",
    "            # 문장 임베딩 생성\n",
    "            part_embedding = self.embedding_model.encode([part])[0]\n",
    "            \n",
    "            # BM25 검색 수행\n",
    "            bm25_scores = self.bm25_index.get_scores(self._simple_tokenize(part))\n",
    "            \n",
    "            if use_vector_db:\n",
    "                # ChromaDB를 사용한 벡터 검색\n",
    "                try:\n",
    "                    part_results = self.vector_db.search(\n",
    "                        query_embeddings=[part_embedding.tolist()],\n",
    "                        n_results=len(self.chunks) // 2  # 각 문장당 검색 결과 수 제한\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    # search 메서드에 문제가 있으면 search_with_embedding 사용\n",
    "                    try:\n",
    "                        part_results = self.vector_db.search_with_embedding(\n",
    "                            embedding=part_embedding.tolist(),\n",
    "                            top_n=len(self.chunks) // 2\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"검색 오류 발생: {str(e)}\")\n",
    "                        # 오류 발생 시 빈 결과 사용\n",
    "                        part_results = []\n",
    "                \n",
    "                # 벡터 점수 초기화\n",
    "                vector_scores = np.zeros(len(self.chunks))\n",
    "                \n",
    "                # 결과를 벡터 점수로 변환\n",
    "                for res in part_results:\n",
    "                    # 문서 ID에서 인덱스 추출\n",
    "                    chunk_id = res.get(\"id\", \"\")\n",
    "                    chunk_index = -1\n",
    "                    \n",
    "                    if \"_\" in chunk_id:\n",
    "                        try:\n",
    "                            chunk_index = int(chunk_id.split(\"_\")[-1])\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                    \n",
    "                    if 0 <= chunk_index < len(self.chunks):\n",
    "                        # 거리를 유사도로 변환 (코사인 거리는 1 - 코사인 유사도)\n",
    "                        similarity = 1.0 - res.get(\"distance\", 0) if res.get(\"distance\") is not None else 0\n",
    "                        vector_scores[chunk_index] = similarity\n",
    "            else:\n",
    "                # 메모리 내 벡터 검색 수행\n",
    "                vector_scores = cosine_similarity([part_embedding], self.vector_index)[0]\n",
    "            \n",
    "            # 하이브리드 점수 계산\n",
    "            combined_scores = self._combine_scores(bm25_scores, vector_scores, alpha)\n",
    "            \n",
    "            # 임계값 이상인 결과 필터링 및 추가\n",
    "            for i, score in enumerate(combined_scores):\n",
    "                if score >= similarity_threshold:\n",
    "                    all_results.append({\n",
    "                        \"chunk_index\": i,\n",
    "                        \"combined_score\": score,\n",
    "                        \"bm25_score\": bm25_scores[i],\n",
    "                        \"vector_score\": vector_scores[i],\n",
    "                        \"query_part\": part\n",
    "                    })\n",
    "        \n",
    "        # 결과 병합 및 중복 제거 (같은 청크는 가장 높은 하이브리드 점수 값 유지)\n",
    "        merged_results = {}\n",
    "        for result in all_results:\n",
    "            chunk_index = result[\"chunk_index\"]\n",
    "            combined_score = result[\"combined_score\"]\n",
    "            \n",
    "            if chunk_index in merged_results:\n",
    "                # 기존 점수보다 높으면 업데이트\n",
    "                if combined_score > merged_results[chunk_index][\"combined_score\"]:\n",
    "                    merged_results[chunk_index] = result\n",
    "            else:\n",
    "                merged_results[chunk_index] = result\n",
    "        \n",
    "        # 하이브리드 점수 기준 내림차순 정렬 후 상위 N개 선택\n",
    "        sorted_results = sorted(\n",
    "            merged_results.values(), \n",
    "            key=lambda x: x[\"combined_score\"], \n",
    "            reverse=True\n",
    "        )[:top_n]\n",
    "        \n",
    "        # 최종 결과 형식 변환\n",
    "        final_results = []\n",
    "        for result in sorted_results:\n",
    "            chunk_index = result[\"chunk_index\"]\n",
    "            final_results.append({\n",
    "                \"chunk\": self.chunks[chunk_index],\n",
    "                \"score\": result[\"combined_score\"],  # 하이브리드 점수\n",
    "                \"bm25_score\": result[\"bm25_score\"],\n",
    "                \"vector_score\": result[\"vector_score\"],\n",
    "                \"memory_score\": 0,  # 추적용\n",
    "                \"index\": chunk_index,\n",
    "                \"page\": self.chunk_metadata[chunk_index][\"page\"],\n",
    "                \"query_part\": result[\"query_part\"]  # 일치한 쿼리 부분 (디버깅용)\n",
    "            })\n",
    "        \n",
    "        return final_results\n",
    "\n",
    "    def page_search(self, query, top_n=5, alpha=0.5, use_vector_db=True):\n",
    "        \"\"\"\n",
    "        하이브리드 검색 수행 후 검색된 청크가 포함된 전체 페이지를 반환\n",
    "        \n",
    "        Args:\n",
    "            query (str): 검색 쿼리\n",
    "            top_n (int): 반환할 결과 수\n",
    "            alpha (float): BM25와 벡터 검색 결과 결합 비율 (0에 가까울수록 벡터 검색 중시)\n",
    "            use_vector_db (bool): ChromaDB 벡터 DB 사용 여부\n",
    "        \n",
    "        Returns:\n",
    "            list: 검색 결과 리스트 (각 결과는 페이지 전체 내용 포함)\n",
    "        \"\"\"\n",
    "        # 기존 mean_search 함수로 청크 검색\n",
    "        chunk_results = self.mean_search(query, top_n, alpha, use_vector_db)\n",
    "        \n",
    "        # 검색된 페이지 번호 추출\n",
    "        found_pages = set(result['page'] for result in chunk_results)\n",
    "        \n",
    "        # 각 페이지의 모든 청크 찾기\n",
    "        page_contents = {}\n",
    "        for page_num in found_pages:\n",
    "            # 해당 페이지의 모든 청크 찾기\n",
    "            page_chunks = []\n",
    "            for i, metadata in enumerate(self.chunk_metadata):\n",
    "                if metadata['page'] == page_num:\n",
    "                    page_chunks.append({\n",
    "                        \"chunk\": self.chunks[i],\n",
    "                        \"index\": i,\n",
    "                        \"page\": page_num\n",
    "                    })\n",
    "            \n",
    "            # 청크 인덱스 순으로 정렬\n",
    "            page_chunks.sort(key=lambda x: x['index'])\n",
    "            \n",
    "            # 페이지 내용 결합\n",
    "            page_content = \"\\n\\n\".join([chunk[\"chunk\"] for chunk in page_chunks])\n",
    "            page_contents[page_num] = page_content\n",
    "        \n",
    "        # 원래 검색 결과의 순서를 유지하면서 페이지 전체 내용으로 대체\n",
    "        full_page_results = []\n",
    "        for result in chunk_results:\n",
    "            page_num = result['page']\n",
    "            full_page_results.append({\n",
    "                \"chunk\": page_contents[page_num],  # 청크 대신 페이지 전체 내용\n",
    "                \"score\": result['score'],\n",
    "                \"bm25_score\": result['bm25_score'],\n",
    "                \"vector_score\": result['vector_score'],\n",
    "                \"memory_score\": result['memory_score'],\n",
    "                \"index\": result['index'],\n",
    "                \"page\": page_num\n",
    "            })\n",
    "        \n",
    "        return full_page_results\n",
    "\n",
    "    def mean_search(self, query, top_n=5, alpha=0.5, use_vector_db=True):\n",
    "        \"\"\"\n",
    "        하이브리드 검색 수행\n",
    "        \n",
    "        Args:\n",
    "            query (str): 검색 쿼리\n",
    "            top_n (int): 반환할 결과 수\n",
    "            alpha (float): BM25와 벡터 검색 결과 결합 비율 (0에 가까울수록 벡터 검색 중시)\n",
    "            use_vector_db (bool): ChromaDB 벡터 DB 사용 여부\n",
    "        \n",
    "        Returns:\n",
    "            list: 검색 결과 리스트\n",
    "        \"\"\"\n",
    "        if self.chunks is None or self.bm25_index is None:\n",
    "            raise ValueError(\"문서가 로드되지 않았습니다. load_document()를 먼저 호출하세요.\")\n",
    "        \n",
    "        if not isinstance(query, str):\n",
    "            query = str(query)\n",
    "        \n",
    "        # 구두점으로 쿼리 분할\n",
    "        query_parts = re.split(r'[.!?;]', query)\n",
    "        query_parts = [part.strip() for part in query_parts if part.strip()]\n",
    "        \n",
    "        # 각 부분에 대한 임베딩 생성\n",
    "        if query_parts:\n",
    "            part_embeddings = self.embedding_model.encode(query_parts)\n",
    "            # 임베딩의 평균 계산\n",
    "            query_embedding = np.mean(part_embeddings, axis=0)\n",
    "        else:\n",
    "            # 분할 결과가 없으면 원래 쿼리 사용\n",
    "            query_embedding = self.embedding_model.encode([query])[0]\n",
    "            \n",
    "        # BM25 검색 수행\n",
    "        bm25_scores = self.bm25_index.get_scores(self._simple_tokenize(query))\n",
    "        \n",
    "        # 두 검색 방식 모두 수행 (디버그 모드)\n",
    "        memory_scores = cosine_similarity([query_embedding], self.vector_index)[0]\n",
    "        \n",
    "        if use_vector_db:\n",
    "            # ChromaDB를 사용한 벡터 검색 - 평균 임베딩 사용\n",
    "            # query 대신 직접 임베딩 벡터 전달\n",
    "            # db_results = self.vector_db.search(\n",
    "            #     query_embeddings=[query_embedding.tolist()], \n",
    "            #     n_results=len(self.chunks)\n",
    "            # )\n",
    "\n",
    "            db_results = self.vector_db.search_with_embedding(\n",
    "                embedding=query_embedding.tolist(), \n",
    "                top_n=len(self.chunks)\n",
    "            )\n",
    "            \n",
    "            # 결과를 벡터 점수로 변환\n",
    "            vector_scores = np.zeros(len(self.chunks))\n",
    "            for res in db_results:\n",
    "                # 문서 ID에서 인덱스 추출\n",
    "                chunk_id = res[\"id\"]\n",
    "                if \"_\" in chunk_id:\n",
    "                    try:\n",
    "                        chunk_index = int(chunk_id.split(\"_\")[-1])\n",
    "                        if chunk_index < len(self.chunks):\n",
    "                            # 거리를 유사도로 변환 (코사인 거리는 1 - 코사인 유사도)\n",
    "                            if res[\"distance\"] is not None:\n",
    "                                # ChromaDB가 코사인 거리를 사용하는 경우\n",
    "                                similarity = 1.0 - res[\"distance\"]\n",
    "                                vector_scores[chunk_index] = similarity\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            \n",
    "            # 디버그 모드에서 점수 비교\n",
    "            if self.debug_mode:\n",
    "                print(\"\\n벡터 검색 점수 비교:\")\n",
    "                for i in range(min(5, len(self.chunks))):\n",
    "                    print(f\"Chunk {i}: Memory={memory_scores[i]:.4f}, ChromaDB={vector_scores[i]:.4f}, 차이={memory_scores[i]-vector_scores[i]:.4f}\")\n",
    "        else:\n",
    "            # 메모리 내 벡터 검색 수행 (기존 방식) - 평균 임베딩 사용\n",
    "            vector_scores = memory_scores\n",
    "        \n",
    "        # 검색 결과 결합\n",
    "        combined_scores = self._combine_scores(bm25_scores, vector_scores, alpha)\n",
    "        \n",
    "        # 상위 N개 결과 반환\n",
    "        top_indices = np.argsort(combined_scores)[-top_n:][::-1]\n",
    "        results = [\n",
    "            {\n",
    "                \"chunk\": self.chunks[i],\n",
    "                \"score\": combined_scores[i],\n",
    "                \"bm25_score\": bm25_scores[i],\n",
    "                \"vector_score\": vector_scores[i],\n",
    "                \"memory_score\": memory_scores[i],  # 디버깅용\n",
    "                \"index\": i,\n",
    "                \"page\": self.chunk_metadata[i][\"page\"]\n",
    "            }\n",
    "            for i in top_indices\n",
    "        ]\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def _split_into_chunks_with_metadata(self, text):\n",
    "        \"\"\"텍스트를 청크로 분할하고 페이지 정보를 메타데이터로 유지하는 함수\"\"\"\n",
    "        chunks = []\n",
    "        chunk_metadata = []\n",
    "        \n",
    "        # 페이지 패턴 정규식 (####으로 시작하는 페이지 헤더)\n",
    "        page_pattern = re.compile(r'####\\s*Page (\\d+)')\n",
    "        \n",
    "        # 텍스트를 줄 단위로 처리\n",
    "        lines = text.split('.')\n",
    "        current_page = \"unknown\"\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for line in lines:\n",
    "            # 페이지 헤더 확인\n",
    "            page_match = page_pattern.match(line)\n",
    "            \n",
    "            if page_match:\n",
    "                # 새 페이지 시작\n",
    "                # 현재 청크가 있으면 저장\n",
    "                if current_chunk.strip():\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                    chunk_metadata.append({\"page\": current_page})\n",
    "                    current_chunk = \"\"\n",
    "                \n",
    "                # 새 페이지 번호 설정\n",
    "                current_page = page_match.group(1)\n",
    "                continue\n",
    "            \n",
    "            # 현재 청크에 라인 추가\n",
    "            current_chunk += line + \"\\n\"\n",
    "            \n",
    "            # 청크 크기 확인\n",
    "            if len(current_chunk) >= self.chunk_size:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                chunk_metadata.append({\"page\": current_page})\n",
    "                current_chunk = \"\"  # 새 청크 시작\n",
    "        \n",
    "        # 마지막 청크 처리\n",
    "        if current_chunk.strip():\n",
    "            chunks.append(current_chunk.strip())\n",
    "            chunk_metadata.append({\"page\": current_page})\n",
    "        \n",
    "        # 너무 작은 청크 결합 (메타데이터 유지)\n",
    "        i = 0\n",
    "        while i < len(chunks) - 1:\n",
    "            if len(chunks[i]) + len(chunks[i+1]) < self.chunk_size:\n",
    "                # 같은 페이지인 경우에만 결합\n",
    "                if chunk_metadata[i][\"page\"] == chunk_metadata[i+1][\"page\"]:\n",
    "                    chunks[i] = chunks[i] + \"\\n\\n\" + chunks[i+1]\n",
    "                    chunks.pop(i+1)\n",
    "                    chunk_metadata.pop(i+1)\n",
    "                else:\n",
    "                    i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        return chunks, chunk_metadata\n",
    "    \n",
    "    def _simple_tokenize(self, text):\n",
    "        \"\"\"텍스트를 간단히 토크나이징하는 함수\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "    \n",
    "    def _combine_scores(self, bm25_scores, vector_scores, alpha=0.5):\n",
    "        \"\"\"BM25와 벡터 검색 점수를 결합\"\"\"\n",
    "        # 점수 정규화\n",
    "        if np.max(bm25_scores) > 0:\n",
    "            bm25_scores = bm25_scores / np.max(bm25_scores)\n",
    "        if np.max(vector_scores) > 0:\n",
    "            vector_scores = vector_scores / np.max(vector_scores)\n",
    "        \n",
    "        # 가중 평균 계산\n",
    "        combined = alpha * bm25_scores + (1 - alpha) * vector_scores\n",
    "        return combined\n",
    "    \n",
    "    def get_chunks_with_page_info(self, indices=None):\n",
    "        \"\"\"청크와 페이지 정보 반환\"\"\"\n",
    "        if indices is None:\n",
    "            return [(chunk, self.chunk_metadata[i][\"page\"]) for i, chunk in enumerate(self.chunks)]\n",
    "        else:\n",
    "            return [(self.chunks[i], self.chunk_metadata[i][\"page\"]) for i in indices if i < len(self.chunks)]\n",
    "    \n",
    "    # 1. 질문이 복합적인지 확인하는 메서드\n",
    "    def is_complex_question(self, question):\n",
    "        \"\"\"\n",
    "        LLM을 사용하여 질문이 복합적인지 판단하는 메서드\n",
    "        \n",
    "        Args:\n",
    "            question (str): 사용자 질문\n",
    "            \n",
    "        Returns:\n",
    "            bool: 복합적인 질문이면 True, 아니면 False\n",
    "        \"\"\"\n",
    "        prompt = self.complexity_prompt.format(question=question)\n",
    "        response = generation_loader.generate(prompt)\n",
    "        \n",
    "        # '예' 또는 'Yes'가 응답에 포함되어 있으면 복합적인 질문으로 간주\n",
    "        response = response.lower().strip()\n",
    "        print(f\"###############질문이 복잡한가요? : {response}\")\n",
    "        return '예' in response or 'yes' in response\n",
    "    \n",
    "    # 2. 복합적인 질문을 하위 질문으로 분해하는 메서드\n",
    "    def decompose_question(self, complex_question):\n",
    "        \"\"\"\n",
    "        LLM을 사용하여 복합적인 질문을 여러 개의 하위 질문으로 분해하는 메서드\n",
    "        \n",
    "        Args:\n",
    "            complex_question (str): 복합적인 사용자 질문\n",
    "            \n",
    "        Returns:\n",
    "            list: 하위 질문 목록\n",
    "        \"\"\"\n",
    "        prompt = self.decompose_prompt.format(question=complex_question)\n",
    "        response = generation_loader.generate(prompt)\n",
    "\n",
    "        try:\n",
    "            # JSON 형식으로 반환된 하위 질문 파싱\n",
    "            # JSON 블록 추출 (```json과 ```로 감싸져 있을 수 있음)\n",
    "            json_match = re.search(r'```json\\s*(.+?)\\s*```', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                response = json_match.group(1)\n",
    "            \n",
    "            # 중괄호 블록 추출\n",
    "            json_match = re.search(r'(\\{.+?\\})', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                response = json_match.group(1)\n",
    "                \n",
    "            sub_questions_data = json.loads(response)\n",
    "            # 다양한 JSON 형식 처리\n",
    "            if isinstance(sub_questions_data, list):\n",
    "                return sub_questions_data\n",
    "            elif isinstance(sub_questions_data, dict):\n",
    "                if \"questions\" in sub_questions_data:\n",
    "                    return sub_questions_data[\"questions\"]\n",
    "                elif \"subQuestions\" in sub_questions_data:\n",
    "                    return sub_questions_data[\"subQuestions\"]\n",
    "                else:\n",
    "                    # 딕셔너리의 값들을 리스트로 반환\n",
    "                    return list(sub_questions_data.values())\n",
    "                \n",
    "        except (json.JSONDecodeError, AttributeError) as e:\n",
    "            print(f\"하위 질문 파싱 오류: {e}\")\n",
    "            print(f\"LLM 응답: {response}\")\n",
    "            \n",
    "            # 파싱 실패 시 줄바꿈을 기준으로 질문 추출 시도\n",
    "            questions = []\n",
    "            for line in response.split('\\n'):\n",
    "                line = line.strip()\n",
    "                if line and ('?' in line or '질문' in line):\n",
    "                    # 숫자, 점, 괄호 등의 접두어 제거\n",
    "                    cleaned_line = re.sub(r'^[\\d\\.\\)\\-\\s]+', '', line).strip()\n",
    "                    if cleaned_line:\n",
    "                        questions.append(cleaned_line)\n",
    "            \n",
    "            if questions:\n",
    "                return questions\n",
    "            # 단일 질문으로 처리\n",
    "            return [complex_question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_loader.config import *\n",
    "from save_utils import *\n",
    "from translate import *\n",
    "\n",
    "class CarManualQA:\n",
    "    def __init__(self, generation_loader, data_folder=\"./data/split_file\", \n",
    "                 prompt_path_ko=\"./prompts/ko/generation/gemma3/generation_prompt2.txt\", \n",
    "                 prompt_path_en=\"./prompts/en/generation/gemma3/generation_prompt2.txt\", \n",
    "                 result_path=\"./result/5월12일/gemma3\",\n",
    "                 use_vector_db=True, \n",
    "                 persist_directory=\"./chroma_db\",\n",
    "                 collection_name=\"Gray\",\n",
    "                 language=\"en\"):\n",
    "        \"\"\"\n",
    "        자동차 매뉴얼 Q&A 시스템 초기화\n",
    "        \n",
    "        Args:\n",
    "            generation_loader: 텍스트 생성 모델 로더\n",
    "            data_folder (str): 분할된 데이터 파일들이 있는 폴더 경로\n",
    "            prompt_path (str): 프롬프트 템플릿 파일 경로\n",
    "            result_path (str): 결과를 저장할 경로\n",
    "            use_vector_db (bool): ChromaDB 벡터 DB 사용 여부\n",
    "            persist_directory (str): 벡터 DB 저장 경로\n",
    "            collection_name (str): 벡터 DB 컬렉션 이름\n",
    "        \"\"\"\n",
    "        self.data_folder = data_folder\n",
    "        self.result_path = result_path\n",
    "        self.use_vector_db = use_vector_db\n",
    "        self.language = language\n",
    "        self.persist_directory = persist_directory\n",
    "        collection_name = f\"{collection_name}\"\n",
    "        \n",
    "        # 하이브리드 검색기 초기화 - ChromaDB 지원 버전\n",
    "        self.searcher = HybridSearcher(\n",
    "            embedding_model=embedding_loader,\n",
    "            chunk_size=200, \n",
    "            chunk_overlap=50,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "        \n",
    "        self.loader = generation_loader\n",
    "        self.prompt_path_ko = prompt_path_ko\n",
    "        self.prompt_path_en = prompt_path_en\n",
    "\n",
    "        if language==\"ko\" :\n",
    "            self.prompt_template = self._load_prompt(prompt_path_ko)\n",
    "        else :\n",
    "            self.prompt_template = self._load_prompt(prompt_path_en)\n",
    "        \n",
    "        # 카테고리별 파일 매핑\n",
    "        if language == \"en\" :\n",
    "            self.category_to_file = {\n",
    "                \"16\": \"GrayAnatomy_Formatted.md\"\n",
    "            }\n",
    "        else :\n",
    "            self.category_to_file = {\n",
    "                \"16\": \"full.txt\"\n",
    "            }\n",
    "        \n",
    "        try :\n",
    "            self.translate_en_to_ko = en_to_ko\n",
    "        except ImportError :\n",
    "            print(\"translate.py 모듈을 임포트할 수 없습니다.\")\n",
    "            self.translate_en_to_ko = en_to_ko\n",
    "\n",
    "        # 이미 처리된 파일 추적\n",
    "        self.loaded_files = set()\n",
    "        \n",
    "        # 전체 파일을 벡터 DB에 미리 로드할지 여부\n",
    "        self.preload_all = False\n",
    "        \n",
    "        # 디버그 모드\n",
    "        self.debug_mode = True\n",
    "        \n",
    "    def preload_documents(self):\n",
    "        \"\"\"\n",
    "        모든 카테고리의 파일을 미리 벡터 DB에 로드\n",
    "        \"\"\"\n",
    "        print(\"모든 문서를 벡터 DB에 로드 중...\")\n",
    "        for category, filename in self.category_to_file.items():\n",
    "            file_path = os.path.join(self.data_folder, filename)\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"카테고리 {category}: {filename} 로드 중...\")\n",
    "                self._load_document(file_path)\n",
    "                self.loaded_files.add(file_path)\n",
    "            else:\n",
    "                print(f\"[경고] 파일을 찾을 수 없습니다: {file_path}\")\n",
    "        \n",
    "        print(f\"총 {len(self.loaded_files)}개 파일이 벡터 DB에 로드되었습니다.\")\n",
    "        self.preload_all = True\n",
    "\n",
    "    # def _load_document(self, file_path):\n",
    "    #     \"\"\"\n",
    "    #     문서를 로드하여 검색기에 추가\n",
    "        \n",
    "    #     Args:\n",
    "    #         file_path (str): 로드할 파일 경로\n",
    "            \n",
    "    #     Returns:\n",
    "    #         int: 로드된 청크 수\n",
    "    #     \"\"\"\n",
    "    #     # 이미 로드된 파일이면 건너뛰기\n",
    "    #     if file_path in self.loaded_files and self.preload_all:\n",
    "    #         if self.debug_mode:\n",
    "    #             print(f\"이미 로드된 파일입니다: {file_path}\")\n",
    "    #         return 0\n",
    "        \n",
    "    #     # 파일 로드 및 벡터 DB에 추가\n",
    "    #     num_chunks = self.searcher.load_document(file_path)\n",
    "        \n",
    "    #     # 파일 추적 목록에 추가\n",
    "    #     self.loaded_files.add(file_path)\n",
    "        \n",
    "    #     if self.debug_mode:\n",
    "    #         print(f\"파일 로드 완료: {file_path} ({num_chunks}개 청크)\")\n",
    "        \n",
    "    #     return num_chunks\n",
    "\n",
    "    def _load_document(self, file_path):\n",
    "        \"\"\"문서 로드 최적화 버전\"\"\"\n",
    "        if isinstance(self.loaded_files, set) :\n",
    "            self.loaded_files={}\n",
    "\n",
    "        # 이미 로드된 파일인지 확인\n",
    "        if file_path in self.loaded_files:\n",
    "            if self.debug_mode:\n",
    "                print(f\"이미 로드된 파일입니다: {file_path}\")\n",
    "            return self.loaded_files[file_path]\n",
    "        \n",
    "        try:\n",
    "            # 1. 캐시 파일 경로 설정\n",
    "            cache_dir = os.path.join(os.path.dirname(file_path), '.cache')\n",
    "            cache_file = os.path.join(cache_dir, os.path.basename(file_path) + '.pickle')\n",
    "            \n",
    "            # 2. 캐시 파일이 존재하고 원본보다 최신이면 캐시 로드\n",
    "            if os.path.exists(cache_file) and os.path.getmtime(cache_file) > os.path.getmtime(file_path):\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    import pickle\n",
    "                    num_chunks = pickle.load(f)\n",
    "                    self.loaded_files[file_path] = num_chunks\n",
    "                    if self.debug_mode:\n",
    "                        print(f\"캐시에서 로드 완료: {file_path}\")\n",
    "                    return num_chunks\n",
    "            \n",
    "            # 3. 캐시 없으면 일반 로드 후 캐시 저장\n",
    "            num_chunks = self.searcher.load_document(file_path)\n",
    "            self.loaded_files[file_path] = num_chunks\n",
    "            \n",
    "            # 캐시 디렉토리 생성\n",
    "            os.makedirs(cache_dir, exist_ok=True)\n",
    "            \n",
    "            # 캐시 파일 저장\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                import pickle\n",
    "                pickle.dump(num_chunks, f)\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                print(f\"로드 및 캐시 저장 완료: {file_path}\")\n",
    "            \n",
    "            return num_chunks\n",
    "        except Exception as e:\n",
    "            print(f\"문서 로드 중 오류 발생: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return 0\n",
    "\n",
    "    def filter_relevant_content(self, query, search_results, threshold=0.7, top_k=5):\n",
    "        \"\"\"\n",
    "        LLM을 사용하여 검색 결과에서 질문과 관련이 있는 내용을 평가하고 \n",
    "        관련성 점수가 높은 상위 k개 결과만 반환\n",
    "        \n",
    "        Args:\n",
    "            query (str): 사용자 질의\n",
    "            search_results (list): 검색 결과 목록\n",
    "            threshold (float): 관련성 점수 임계값 (0.0~1.0)\n",
    "            top_k (int): 반환할 상위 결과 개수\n",
    "            \n",
    "        Returns:\n",
    "            list: 점수가 높은 상위 k개의 필터링된 관련 정보 목록\n",
    "        \"\"\"\n",
    "        scored_results = []\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            print(f\"검색 결과 {len(search_results)}개에 대한 관련성 필터링 시작\")\n",
    "        \n",
    "        # 각 검색 결과에 대해 관련성 평가\n",
    "        for result in search_results:\n",
    "            # 프롬프트 구성 - 관련성 평가용\n",
    "            relevance_prompt = f\"\"\"\n",
    "    다음은 사용자의 질문입니다:\n",
    "    \"{query}\"\n",
    "    다음은 검색된 텍스트 정보입니다:\n",
    "    \"{result['chunk']}\"\n",
    "    위 텍스트가 사용자 질문에 얼마나 관련이 있는지 평가해주세요.\n",
    "    평가는 다음과 같이 응답해주세요:\n",
    "    1. 관련성 점수: 0.0 ~ 1.0 사이의 숫자 (1.0이 가장 관련성 높음)\n",
    "    2. 이유: 관련성이 높거나 낮은 이유를 간략하게 설명\n",
    "    응답 형식:\n",
    "    {{\n",
    "    \"score\": 0.0~1.0,\n",
    "    \"reason\": \"평가 이유\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "            \n",
    "            relevance_result = self.loader.generate(relevance_prompt)\n",
    "            \n",
    "            try:\n",
    "                # JSON 응답 파싱 (정확한 JSON이 아닐 수 있으므로 예외 처리)\n",
    "                import re\n",
    "                import json\n",
    "                \n",
    "                # JSON 형식 추출 시도\n",
    "                json_match = re.search(r'\\{.*\"score\".*:.*,.*\"reason\".*:.*\\}', relevance_result, re.DOTALL)\n",
    "                if json_match:\n",
    "                    relevance_data = json.loads(json_match.group(0))\n",
    "                    score = float(relevance_data.get(\"score\", 0))\n",
    "                else:\n",
    "                    # 숫자만 추출 시도\n",
    "                    score_match = re.search(r'score\"?\\s*:?\\s*(\\d+\\.\\d+|\\d+)', relevance_result)\n",
    "                    score = float(score_match.group(1)) if score_match else 0.0\n",
    "                \n",
    "                # 점수와 함께 결과 저장 (임계값 이상인 것만)\n",
    "                if score >= threshold:\n",
    "                    if self.debug_mode:\n",
    "                        print(f\"관련성 높음 (점수: {score:.2f}): {result['page']}페이지\")\n",
    "                    # 원본 결과에 점수 정보 추가\n",
    "                    result_with_score = result.copy()\n",
    "                    result_with_score['relevance_score'] = score\n",
    "                    scored_results.append(result_with_score)\n",
    "                else:\n",
    "                    if self.debug_mode:\n",
    "                        print(f\"관련성 낮음 (점수: {score:.2f}): {result['page']}페이지\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # 파싱 실패 시 안전을 위해 낮은 점수로 포함\n",
    "                if self.debug_mode:\n",
    "                    print(f\"관련성 평가 파싱 오류: {str(e)}\")\n",
    "                result_with_score = result.copy()\n",
    "                result_with_score['relevance_score'] = 0.1  # 낮은 기본 점수\n",
    "                scored_results.append(result_with_score)\n",
    "        \n",
    "        # 점수를 기준으로 내림차순 정렬\n",
    "        sorted_results = sorted(scored_results, key=lambda x: x['relevance_score'], reverse=True)\n",
    "        \n",
    "        # 상위 k개 결과만 선택\n",
    "        top_results = sorted_results[:top_k]\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            print(f\"필터링 결과: 총 {len(search_results)}개 중 {len(scored_results)}개가 임계값 통과\")\n",
    "            print(f\"상위 {min(top_k, len(top_results))}개 결과만 선택됨\")\n",
    "            for i, res in enumerate(top_results):\n",
    "                print(f\"  {i+1}위: 점수 {res['relevance_score']:.2f} - {res['page']}페이지\")\n",
    "        \n",
    "        # 결과가 없는 경우 원본의 일부라도 반환\n",
    "        if not top_results and search_results:\n",
    "            if self.debug_mode:\n",
    "                print(f\"필터링 결과가 없어 원본 상위 결과 {min(top_k, len(search_results))}개 포함\")\n",
    "            top_results = search_results[:min(top_k, len(search_results))]\n",
    "        \n",
    "        return top_results\n",
    "    \n",
    "    def _format_filtered_results(self, filtered_results):\n",
    "        \"\"\"\n",
    "        필터링된 결과를 문자열로 변환\n",
    "        \n",
    "        Args:\n",
    "            filtered_results (list): 필터링된 검색 결과 리스트\n",
    "            \n",
    "        Returns:\n",
    "            str: 포맷된 문자열\n",
    "        \"\"\"\n",
    "        result_str = \"\"\n",
    "        \n",
    "        for item in filtered_results:\n",
    "            result_str += f\"# 질문: {item['sub_question']}\\n\\n\"\n",
    "            \n",
    "            # results가 이미 점수로 정렬되었다고 가정\n",
    "            for res in item['results']:\n",
    "                page_info = res['page']\n",
    "                score_info = \"\"\n",
    "                if 'relevance_score' in res:\n",
    "                    score_info = f\" (관련성: {res['relevance_score']:.2f})\"\n",
    "                \n",
    "                result_str += f\"## {page_info}페이지{score_info}\\n\"\n",
    "                result_str += f\"{res['chunk']}\\n\\n\"\n",
    "        \n",
    "        return result_str\n",
    "\n",
    "    def _generate_hypothetical_document(self, query):\n",
    "        \"\"\"\n",
    "        질문에 대한 가상 문서 생성 (Hyde 기법)\n",
    "        \n",
    "        Args:\n",
    "            query (str): 사용자 질의\n",
    "            \n",
    "        Returns:\n",
    "            str: 생성된 가상 문서\n",
    "        \"\"\"\n",
    "        # Hyde 프롬프트 템플릿\n",
    "        hyde_prompt = \"\"\"Write a concise and accurate hypothetical document content for the following question:\n",
    "Question: {query}\n",
    "Guidelines:\n",
    "1. Include only essential information in 200-300 words.\n",
    "2. Be sure to include important keywords and technical terminology related to the question.\n",
    "3. Limit to 2-3 paragraphs, with each paragraph addressing a clear topic.\n",
    "4. Focus on facts and omit unnecessary explanations or examples.\n",
    "5. Write in an objective style as would appear in a professional reference or textbook.\n",
    "6. This document should be optimized for vector search. Therefore, include abundant relevant terminology and synonyms while keeping the overall length short.\n",
    "7. Do not use any markdown syntax in your response.\n",
    "\"\"\"\n",
    "            \n",
    "        prompt = hyde_prompt.format(query=query)\n",
    "        \n",
    "        # LLM을 사용하여 가상 문서 생성\n",
    "        if hasattr(self.loader, \"tokenizer\"):\n",
    "            tokenizer = self.loader.tokenizer\n",
    "            model = self.loader.model\n",
    "            \n",
    "            # 인풋 토크나이즈\n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "            attention_mask = (input_ids != tokenizer.pad_token_id).long().to(model.device)\n",
    "            \n",
    "            # 텍스트 생성\n",
    "            output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=400,\n",
    "                temperature=0.7,  \n",
    "                do_sample=True,\n",
    "                top_p=0.85,\n",
    "                repetition_penalty=1.2,\n",
    "                early_stopping=True,\n",
    "                num_beams=1,  \n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "            generated_ids = output[0][input_ids.shape[-1]:]\n",
    "            hypothetical_doc = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "        else:\n",
    "            # OpenAI 등 API 기반 모델 사용\n",
    "            hypothetical_doc = self.loader.generate(prompt)\n",
    "        \n",
    "        return hypothetical_doc\n",
    "\n",
    "    # def search_across_collections(self, query, top_n=5, alpha=0.5):\n",
    "    #     \"\"\"모든 컬렉션에서 HyDE 기법을 사용한 검색 후 점수 기준 상위 결과 반환\"\"\"\n",
    "        \n",
    "    #     collections = [\"1_Embryology\", \"2_Osteology\", \"3_Syndesmology\", \"4_Myology\", \n",
    "    #                 \"5_Angiology\", \"6_The_Arteries\", \"7_The_Veins\", \"8_The_Lymphatic_System\", \n",
    "    #                 \"9_Neurology\", \"10_The_Organs_of_the_Senses_and_the_Common_Integument\", \n",
    "    #                 \"11_Splanchnology\", \"12_Surface_Anatomy_and_Surface_Markings\"]\n",
    "        \n",
    "    #     # HyDE 기법 적용\n",
    "    #     hyde_start = time.time()\n",
    "    #     hypothetical_doc = self._generate_hypothetical_document(query)\n",
    "    #     if self.debug_mode:\n",
    "    #         print(f\"가상 문서 : {hypothetical_doc}\")\n",
    "    #     hyde_end = time.time()\n",
    "    #     if self.debug_mode:\n",
    "    #         print(f\"가상 문서 생성 시간 : {hyde_end - hyde_start}\")\n",
    "        \n",
    "    #     all_results = []\n",
    "        \n",
    "        \n",
    "    #     for collection_name in collections:\n",
    "    #         print(f\"################{collection_name} 검색 실행################\")\n",
    "    #         # 임시로 컬렉션 변경\n",
    "    #         original_collection = self.searcher.collection_name\n",
    "    #         self.searcher.collection_name = collection_name\n",
    "            \n",
    "    #         try:\n",
    "    #             # 각 컬렉션에서 HyDE 문서로 검색\n",
    "    #             results = self.searcher.mean_search(\n",
    "    #                 query=hypothetical_doc, \n",
    "    #                 top_n=top_n * 2,  # 더 많이 가져와서 선택의 폭을 넓힘\n",
    "    #                 alpha=alpha,\n",
    "    #                 use_vector_db=self.use_vector_db\n",
    "    #             )\n",
    "                \n",
    "    #             print(f\"{collection_name}에서 {len(results)}개 결과 검색됨\")\n",
    "    #             # 컬렉션 정보 추가\n",
    "    #             for result in results:\n",
    "    #                 result['collection'] = collection_name\n",
    "    #                 all_results.append(result)\n",
    "                    \n",
    "    #         except Exception as e:\n",
    "    #             print(f\"컬렉션 {collection_name} 검색 중 오류: {e}\")\n",
    "    #             continue\n",
    "    #         finally:\n",
    "    #             # 원래 컬렉션으로 복구\n",
    "    #             self.searcher.collection_name = original_collection\n",
    "        \n",
    "    #     # 점수 기준 정렬 후 상위 top_n개 반환\n",
    "    #     all_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    #     return all_results[:top_n]\n",
    "\n",
    "    def search_across_collections(self, query, top_n=5, alpha=0.5):\n",
    "        \"\"\"모든 컬렉션에서 HyDE 기법을 사용한 검색 후 점수 기준 상위 결과 반환\"\"\"\n",
    "        \n",
    "        collections = [\"1_Embryology\", \"2_Osteology\", \"3_Syndesmology\", \"4_Myology\", \n",
    "                    \"5_Angiology\", \"6_The_Arteries\", \"7_The_Veins\", \"8_The_Lymphatic_System\", \n",
    "                    \"9_Neurology\", \"10_The_Organs_of_the_Senses_and_the_Common_Integument\", \n",
    "                    \"11_Splanchnology\", \"12_Surface_Anatomy_and_Surface_Markings\"]\n",
    "        \n",
    "        # HyDE 기법 적용\n",
    "        hyde_start = time.time()\n",
    "        hypothetical_doc = self._generate_hypothetical_document(query)\n",
    "        if self.debug_mode:\n",
    "            print(f\"가상 문서 : {hypothetical_doc}\")\n",
    "        \n",
    "        # HyDE 문서가 비어있는지 확인\n",
    "        if not hypothetical_doc or len(hypothetical_doc.strip()) == 0:\n",
    "            print(\"HyDE 문서 생성 실패 - 원본 쿼리 사용\")\n",
    "            hypothetical_doc = query\n",
    "        \n",
    "        hyde_end = time.time()\n",
    "        if self.debug_mode:\n",
    "            print(f\"가상 문서 생성 시간 : {hyde_end - hyde_start}\")\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        # ChromaDB 클라이언트 한 번만 생성\n",
    "        try:\n",
    "            client = chromadb.PersistentClient(path=self.searcher.persist_directory)\n",
    "            available_collections = [col.name for col in client.list_collections()]\n",
    "            print(f\"사용 가능한 컬렉션: {available_collections}\")\n",
    "            \n",
    "            # 사용 가능한 컬렉션이 없는 경우\n",
    "            if not available_collections:\n",
    "                print(\"사용 가능한 컬렉션이 없습니다!\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ChromaDB 클라이언트 연결 실패: {e}\")\n",
    "            return []\n",
    "        \n",
    "        for collection_name in collections:\n",
    "            try:\n",
    "                # 컬렉션 존재 여부 확인\n",
    "                if collection_name not in available_collections:\n",
    "                    print(f\"컬렉션 {collection_name}이 존재하지 않습니다. 건너뜁니다.\")\n",
    "                    continue\n",
    "                    \n",
    "                # 기존 컬렉션 가져오기\n",
    "                collection = client.get_collection(\n",
    "                    name=collection_name,\n",
    "                    embedding_function=self.searcher.vector_db.embedding_function\n",
    "                )\n",
    "                \n",
    "                # 컬렉션 크기 확인\n",
    "                collection_count = collection.count()\n",
    "                print(f\"현재 검색 중인 컬렉션: {collection_name} (문서 수: {collection_count})\")\n",
    "                \n",
    "                if collection_count == 0:\n",
    "                    print(f\"컬렉션 {collection_name}이 비어있습니다.\")\n",
    "                    continue\n",
    "                \n",
    "                # 쿼리 임베딩 생성 (HyDE 문서 사용)\n",
    "                try:\n",
    "                    query_embedding = self.searcher.embedding_model.encode([hypothetical_doc])[0]\n",
    "                    print(f\"임베딩 생성 완료: 차원 = {len(query_embedding)}\")\n",
    "                except Exception as embed_error:\n",
    "                    print(f\"임베딩 생성 실패: {embed_error}\")\n",
    "                    continue\n",
    "                \n",
    "                # ChromaDB에서 벡터 검색\n",
    "                db_results = collection.query(\n",
    "                    query_embeddings=[query_embedding.tolist()],\n",
    "                    n_results=min(top_n * 2, collection_count),\n",
    "                    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "                )\n",
    "                \n",
    "                print(f\"{collection_name}에서 {len(db_results['documents'][0]) if db_results['documents'] else 0}개 결과 검색됨\")\n",
    "                \n",
    "                # 결과가 실제로 있는지 확인\n",
    "                if not db_results['documents'] or not db_results['documents'][0]:\n",
    "                    print(f\"컬렉션 {collection_name}에서 검색 결과 없음\")\n",
    "                    continue\n",
    "                \n",
    "                # 결과 포맷 변환\n",
    "                for i in range(len(db_results['documents'][0])):\n",
    "                    # 메타데이터에서 페이지 정보 추출\n",
    "                    metadata = db_results['metadatas'][0][i] if db_results['metadatas'] else {}\n",
    "                    page_info = metadata.get('page', f'Page {i+1}')\n",
    "                    \n",
    "                    result = {\n",
    "                        \"chunk\": db_results['documents'][0][i],\n",
    "                        \"score\": 1.0 - db_results['distances'][0][i] if db_results['distances'] else 0.5,\n",
    "                        \"bm25_score\": 0,\n",
    "                        \"vector_score\": 1.0 - db_results['distances'][0][i] if db_results['distances'] else 0.5,\n",
    "                        \"memory_score\": 1.0 - db_results['distances'][0][i] if db_results['distances'] else 0.5,\n",
    "                        \"index\": db_results['ids'][0][i] if db_results['ids'] else f\"{collection_name}_{i}\",\n",
    "                        \"page\": page_info,\n",
    "                        \"collection\": collection_name\n",
    "                    }\n",
    "                    all_results.append(result)\n",
    "                \n",
    "                if db_results['documents'][0]:\n",
    "                    print(f\"첫 번째 결과 페이지: {metadata.get('page', 'page 정보 없음')}\")\n",
    "                    print(f\"첫 번째 결과 일부: {db_results['documents'][0][0][:100]}...\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"컬렉션 {collection_name} 검색 중 오류: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        print(f\"총 검색된 결과 수: {len(all_results)}\")\n",
    "        \n",
    "        # 점수 기준 정렬 후 상위 top_n개 반환\n",
    "        if all_results:\n",
    "            all_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "            \n",
    "            # 중복 제거\n",
    "            seen_chunks = set()\n",
    "            unique_results = []\n",
    "            for result in all_results:\n",
    "                chunk_hash = hash(result['chunk'][:100])\n",
    "                if chunk_hash not in seen_chunks:\n",
    "                    seen_chunks.add(chunk_hash)\n",
    "                    unique_results.append(result)\n",
    "                    if len(unique_results) >= top_n:\n",
    "                        break\n",
    "            \n",
    "            print(f\"전체 {len(all_results)}개 결과에서 중복 제거 후 상위 {len(unique_results)}개 선택\")\n",
    "            return unique_results\n",
    "        else:\n",
    "            print(\"검색 결과가 없습니다.\")\n",
    "            return []\n",
    "\n",
    "    def generate_response(self, query, category, top_n=5, alpha=0.5, target_language=None, idx=1):\n",
    "        \"\"\"\n",
    "        질의에 대한 응답 생성\n",
    "        \n",
    "        Args:\n",
    "            query (str): 사용자 질의\n",
    "            category (str): 검색할 카테고리\n",
    "            top_n (int): 검색 결과 수\n",
    "            alpha (float): BM25와 벡터 검색 가중치 (높을수록 BM25 중시)\n",
    "            \n",
    "        Returns:\n",
    "            dict: 생성된 응답 및 메타데이터\n",
    "        \"\"\"\n",
    "        import time\n",
    "        try:\n",
    "            response_language = target_language if target_language else self.language\n",
    "            source_language = self.language\n",
    "\n",
    "            ####################### Hyde 기법 #######################\n",
    "            hyde_start = time.time()\n",
    "            hypothetical_doc = self._generate_hypothetical_document(query)\n",
    "            if self.debug_mode:\n",
    "                print(f\"가상 문서 : {hypothetical_doc}\")\n",
    "            hyde_end = time.time()\n",
    "            if self.debug_mode:\n",
    "                print(f\"가상 문서 생성 시간 : {hyde_end - hyde_start}\")\n",
    "\n",
    "            # search_start = time.time()\n",
    "            # search_results = self.search_across_collections(query, top_n=top_n, alpha=alpha)\n",
    "            # search_end = time.time()\n",
    "            # if self.debug_mode :\n",
    "            #     print(\"검색 시간 : \", search_end - search_start)\n",
    "            ####################################################################################\n",
    "            # search_results = self.searcher.search( # 검색\n",
    "            #     query=query, \n",
    "            #     top_n=top_n, \n",
    "            #     alpha=alpha,\n",
    "            #     use_vector_db=self.use_vector_db\n",
    "            #     )   \n",
    "            ####################################################################################\n",
    "            # search_results = self.searcher.multi_sentence_hybrid_search( \n",
    "            #     query=hypothetical_doc, \n",
    "            #     top_n=top_n, \n",
    "            #     similarity_threshold=0.7,\n",
    "            #     alpha=alpha,\n",
    "            #     use_vector_db=self.use_vector_db\n",
    "            #     )   \n",
    "            ####################################################################################\n",
    "            search_start = time.time()\n",
    "            \n",
    "            search_results = self.searcher.multi_collection_search( \n",
    "                query=hypothetical_doc, \n",
    "                top_n_per_collection=5, \n",
    "                alpha=alpha,\n",
    "                final_top_n=10\n",
    "                )   \n",
    "            \n",
    "            print(\"##############################다중 컬렉션 검색 결과 : \", search_results)\n",
    "            \n",
    "            search_end = time.time()\n",
    "            if self.debug_mode :\n",
    "                print(\"검색 시간 : \", search_end - search_start)\n",
    "            ####################################################################################\n",
    "            # search_results = self.searcher.page_search(\n",
    "            #     query=hypothetical_doc, \n",
    "            #     top_n=top_n, \n",
    "            #     alpha=alpha,\n",
    "            #     use_vector_db=self.use_vector_db\n",
    "            # )\n",
    "\n",
    "            # context 생성 부분\n",
    "            context = \"\\n\\n\".join([f\"#### Page {result['page']}\\n{result['chunk']}\" for result in search_results])\n",
    "\n",
    "            prompt = self.prompt_template.format(context=context, query=query)\n",
    "\n",
    "            generation_start = time.time()\n",
    "            # 응답 생성 파트\n",
    "            if hasattr(self.loader, \"tokenizer\"):\n",
    "                # Huggingface 모델 사용\n",
    "                tokenizer = self.loader.tokenizer\n",
    "                model = self.loader.model\n",
    "                \n",
    "                # 인풋 토크나이즈\n",
    "                input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "                attention_mask = (input_ids != tokenizer.pad_token_id).long().to(model.device)\n",
    "                \n",
    "                # 텍스트 생성\n",
    "                output = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=400,\n",
    "                    temperature=0.3,\n",
    "                    do_sample=False,\n",
    "                    top_p=0.85,\n",
    "                    repetition_penalty=1.2,\n",
    "                    early_stopping=True,\n",
    "                    num_beams=3,\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "                generated_ids = output[0][input_ids.shape[-1]:]\n",
    "                raw_answer = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "            else:\n",
    "                # OpenAI 등 API 기반 모델 사용 (Ollama 포함)\n",
    "                raw_answer = self.loader.generate(prompt)\n",
    "            generation_end = time.time()\n",
    "            if self.debug_mode :\n",
    "                print(\"응답 생성 시간 : \", generation_end - generation_start)\n",
    "\n",
    "            # 응답 후처리\n",
    "            final_answer = self._extract_answer_content(raw_answer)\n",
    "            final_answer = self._remove_chinese_characters(final_answer)\n",
    "            \n",
    "            translated_answer = None\n",
    "            if source_language == \"en\" and response_language == \"ko\" :\n",
    "                if self.translate_en_to_ko :\n",
    "                    try :\n",
    "                        translate_start = time.time()\n",
    "                        translated_answer = self.translate_en_to_ko(final_answer)\n",
    "                        translate_end = time.time()\n",
    "                        if self.debug_mode :\n",
    "                            print(\"영어 -> 한국어 번역 완료, 번역 시간 : \", translate_end - translate_start)\n",
    "                    except Exception as e :\n",
    "                        print(f\"번역 중 오류 발생 : {e}\")\n",
    "                        translated_answer = f\"[번역 오류] {final_answer}\"\n",
    "                else :\n",
    "                    translated_answer = f\"[번역 모듈 없음] {final_answer}\"\n",
    "            # 결과 준비\n",
    "            response = {\n",
    "                \"답변\": raw_answer,\n",
    "                \"후처리\": final_answer,\n",
    "                \"문서 일부\": context,\n",
    "                \"question_en\": query,\n",
    "                \"answer_en\": raw_answer,\n",
    "                # \"is_complex\": is_complex,\n",
    "                # \"필터링_결과\": all_filtered_results\n",
    "            }\n",
    "            \n",
    "            if translated_answer :\n",
    "                response[\"번역된 답변\"] = translated_answer\n",
    "                \n",
    "            \n",
    "            # 결과 저장\n",
    "            try:\n",
    "                # result_path가 없으면 상위 스코프나 기본값으로 설정\n",
    "                result_path = getattr(self, 'result_path', '../result')\n",
    "                \n",
    "                \n",
    "                # 폴더가 없으면 생성\n",
    "                os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "                # 파일 저장\n",
    "                if self.debug_mode:\n",
    "                    print(f\"저장 시도: {result_path}\")\n",
    "                save_response_to_file(\n",
    "                    query=query,\n",
    "                    answer=response[\"답변\"],\n",
    "                    # final_answer=response[\"번역된 답변\"],\n",
    "                    context=response[\"문서 일부\"],\n",
    "                    folder=result_path,\n",
    "                    # hypothetical_doc=hypothetical_doc,\n",
    "                    idx=idx\n",
    "                    # filtered_results=filtered_results_str\n",
    "                )\n",
    "                if self.debug_mode:\n",
    "                    print(f\"저장 완료: {result_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"결과 저장 중 오류 발생: {e}\")\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"[생성 오류] {str(e)}\"\n",
    "            print(error_msg)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {\"답변\": error_msg, \"후처리\": error_msg}\n",
    "    \n",
    "    def _load_prompt(self, path):\n",
    "        \"\"\"프롬프트 템플릿 로드\"\"\"\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 프롬프트 로드 실패: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _extract_answer_content(self, text):\n",
    "        \"\"\"응답에서 답변 부분만 추출\"\"\"\n",
    "        pattern = r\"(?:<\\|?|<|)?\\|?answer\\|?(?:\\|?>|>)?(.*?)(?:<\\|?|<|)?\\|?endanswer\\|?(?:\\|?>|>)?\"\n",
    "        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        return match.group(1).strip() if match else text.strip()\n",
    "    \n",
    "    def _remove_chinese_characters(self, text):\n",
    "        \"\"\"중국어 문자 제거\"\"\"\n",
    "        return re.sub(r'[\\u4E00-\\u9FFF]', '', text)\n",
    "    \n",
    "    def get_collection_stats(self):\n",
    "        \"\"\"벡터 DB 컬렉션 통계 조회\"\"\"\n",
    "        if hasattr(self.searcher, 'vector_db') and hasattr(self.searcher.vector_db, 'get_collection_stats'):\n",
    "            return self.searcher.vector_db.get_collection_stats()\n",
    "        return {\"error\": \"벡터 DB 통계를 조회할 수 없습니다.\"}\n",
    "    \n",
    "    def toggle_vector_db(self, use_vector_db=None):\n",
    "        \"\"\"벡터 DB 사용 여부 전환\"\"\"\n",
    "        if use_vector_db is not None:\n",
    "            self.use_vector_db = use_vector_db\n",
    "        else:\n",
    "            self.use_vector_db = not self.use_vector_db\n",
    "        \n",
    "        print(f\"벡터 DB 사용 여부: {self.use_vector_db}\")\n",
    "        return self.use_vector_db\n",
    "    \n",
    "    def set_debug_mode(self, debug_mode=True):\n",
    "        \"\"\"디버그 모드 설정\"\"\"\n",
    "        self.debug_mode = debug_mode\n",
    "        return self.debug_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27262ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_db = ChromaVectorDB(\n",
    "#     embedding_model=embedding_loader,\n",
    "#     persist_directory=\"./chroma_db\",\n",
    "#     collection_name=\"Gray_en\"\n",
    "# )\n",
    "# vector_db.delete_collection()\n",
    "# print(\"기존 컬렉션 삭제 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5028beb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 컬렉션 'Gray'을 로드했습니다.\n",
      "\n",
      "======================Alpha 값 : 0.7======================\n",
      "\n",
      "새 쿼리: How many bones make up the adult human skeleton?, 카테고리: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sangwon/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가상 문서 : 8. Keep the tone informative and factual. Avoid using personal opinions, jokes, colloquialisms, slang, etc.  | Introduction |\n",
      "The adult human skeleton is composed of numerous interconnected elements that support the body structure, protect vital organs, facilitate movement, and provide attachment points for muscles. Understanding this complex system can help individuals appreciate its importance in maintaining health and wellness throughout life. Here we examine the number of bones making up the human skeletal framework.| Bones of the Adult Human Skeleton |\n",
      "According to standard biological classification, the human adult skeleton consists of 206 distinct bones. These are organized into four primary categories: axial (core) and appendicular (limb) structures. The axial skeleton includes the skull, vertebral column, ribcage, sternum, sacrum, coccyx, and thoracic cage components; whereas the appendicular skeleton encompasses all limbs' constituents - upper arm, forearm, hand, lower leg, thigh, pelvis, shoulder girdle, and scapulae. Some specialized terms used in describing these bones include long, flat, irregular, sesamoid, and saddle-shaped, among others. For instance, the femur (thigh bone), tibia (shin bone), fibula (leg bone), clavicle (collarbone), humerus (upper arm bone), and ulna/radius (forearm bones) fall under the long bone category. On the other hand, the carpal (wrist) and metatarsal (foot) bones represent the flat type, such as those found within our hands and feet. Additionally, some bones exhibit unique characteristics like the patella (kneecap) which belongs to the sesamoid group due to its distinctive shape and function. Lastly, the s\n",
      "가상 문서 생성 시간 : 96.13740015029907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e789054828b4550aacd17bf6d6a77ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################다중 컬렉션 검색 결과 :  [{'chunk': 'The bones belonging to this class are: the clavicle, humerus, radius, ulna, femur, tibia, fibula,\\nmetacarpals, metatarsals, and phalanges\\n\\n\\nShort Bones\\n —Where a part of the skeleton is intended for strength and compactness combined with\\nlimited movement, it is constructed of a number of short bones, as in the carpu s and tarsus', 'score': 0.6268966197967529, 'bm25_score': 0.0, 'vector_score': 0.6268966197967529, 'memory_score': 0.6268966197967529, 'index': 0, 'page': '37', 'collection': '2_Osteology'}, {'chunk': '1\\n\\n\\nIn the skeleton of the adult there are 206 distinct bones, as follows:— 2\\n\\n\\nAxial\\n\\nSkeleton\\n\\n\\nVertebral column 26\\n\\nSkull 22\\n\\nHyoid bone 1\\n\\nRibs and sternum 25\\n\\n\\n— 74\\n\\nAppendicular Upper extremities 64\\n\\n\\nSkeleton\\n\\n\\nUpper extremities 64\\n\\nLower extremities 62\\n\\n\\n— 126\\n\\nAuditory ossicles 6\\n\\n—\\n\\nTotal 206\\n\\nThe patellæ are included in this enumeration, but the smaller sesamoid bones are not reckoned', 'score': 0.6259458959102631, 'bm25_score': 0.0, 'vector_score': 0.6259458959102631, 'memory_score': 0.6259458959102631, 'index': 1, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'A short perforation is called a foramen, a longer passage a canal\\n\\n## 1\\n Development of the Skeleton\\n\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n\\n\\n#### Page 38\\n\\nThe Skeleton\\n —The skeleton is of mesodermal origin, and may be divided into ( a ) that of the trunk ( axial\\nskeleton ), comprising the vertebral column, skull, ribs, and sternum, and ( b ) that of the limbs ( appendicular\\nskeleton )', 'score': 0.5924633145332336, 'bm25_score': 0.0, 'vector_score': 0.5924633145332336, 'memory_score': 0.5924633145332336, 'index': 2, 'page': '37', 'collection': '2_Osteology'}, {'chunk': '3\\n\\nBones are divisible into four classes: Long, Short, Flat, and Irregular\\n 4\\n\\n\\nLong Bones\\n —The long bones are found in the limbs, and each consists of a body or shaft and two\\nextremities\\n The body, or diaphysi s is cylindrical, with a central cavity termed the medullary canal ; the wall\\nconsists of dense, compact tissue of considerable thickness in the middle part of the body, but becoming\\nthinner toward the extremities; within the medullary canal is some cancellous tissue, scanty in the middle of\\nthe body but greater in amount toward the ends', 'score': 0.5875040590763092, 'bm25_score': 0.0, 'vector_score': 0.5875040590763092, 'memory_score': 0.5875040590763092, 'index': 3, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'It is divisible into two parts: (1) the cranium, which lodges and protects the brain,\\nconsists of eight bones, and (2) the skeleton of the face, of fourteen, as follows:\\n\\nSkull, 22 bones Cranium, 8 bones  Occipital', 'score': 0.5830719470977783, 'bm25_score': 0.0, 'vector_score': 0.5830719470977783, 'memory_score': 0.5830719470977783, 'index': 4, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'In the limbs, they are of considerable length, especially the more\\nsuperficial ones; they surround the bones, and constitute an important protection to the various joints\\n In the\\ntrunk, they are broad, flattened, and expanded, and assist in forming the walls of the trunk cavities', 'score': 0.5760789513587952, 'bm25_score': 0.0, 'vector_score': 0.5760789513587952, 'memory_score': 0.5760789513587952, 'index': 0, 'page': '243', 'collection': '4_Myology'}, {'chunk': ', the cartilage of the\\nseptum, the two lateral and the two greater alar cartilages, and several smaller pieces, the lesser alar\\ncartilages ( Figs\\n 852, 853, 854)\\n The various cartilages are connected to each other and to the bones by a\\ntough fibrous membrane', 'score': 0.5747600495815277, 'bm25_score': 0.0, 'vector_score': 0.5747600495815277, 'memory_score': 0.5747600495815277, 'index': 0, 'page': '623', 'collection': '10_The_Organs_of_the_Senses_and_the_Common_Integument'}, {'chunk': 'Each of these consists from below upward, of\\nthree parts, as follows:\\n\\nLateral Column\\n Intermediate Column\\n Medial Column\\n\\n\\nIliocostalis\\n Longissimus\\n Spinalis\\n\\n( a ) I\\n lumborum\\n  ( a ) L\\n dorsi\\n ( a ) S', 'score': 0.5642812848091125, 'bm25_score': 0.0, 'vector_score': 0.5642812848091125, 'memory_score': 0.5642812848091125, 'index': 1, 'page': '243', 'collection': '4_Myology'}, {'chunk': 'Bone\\n —Bone constitutes the fundamental element of all the joints\\n In the long bones, the extremities are the\\nparts which form the articulations; they are generally somewhat enlarged; and consist of spongy cancellous\\ntissue with a thin coating of compact substance', 'score': 0.5609582662582397, 'bm25_score': 0.0, 'vector_score': 0.5609582662582397, 'memory_score': 0.5609582662582397, 'index': 0, 'page': '174', 'collection': '3_Syndesmology'}, {'chunk': '1\\n\\n\\nThe bones are connected together by the following ligaments: 2\\n\\n\\nThe Articular Capsule\\n The Anterior Cruciate\\n\\nThe Ligamentum Patellæ\\n The Posterior Cruciate\\n\\nThe Oblique Popliteal\\n The Medial and Lateral Menisci', 'score': 0.5534813106060028, 'bm25_score': 0.0, 'vector_score': 0.5534813106060028, 'memory_score': 0.5534813106060028, 'index': 1, 'page': '174', 'collection': '3_Syndesmology'}]\n",
      "검색 시간 :  0.40057873725891113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sangwon/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/sangwon/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.85` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답 생성 시간 :  514.4295156002045\n",
      "저장 시도: ./result/5월23일\n",
      "저장 완료: ./result/5월23일\n",
      "추론시간 : 610.9728672504425\n",
      "LLM 답변: [Your Required Answer]\n",
      "According to page 37, in the skeleton of the adult there are 206 distinct bones. \n",
      "\n",
      "[Document]\n",
      "#### Page 37\n",
      "The bones belonging to this class are: the clavicle, humerus, radius, ulna, femur, tibia, fibula,\n",
      "metacarpals, metatarsals, and phalanges\n",
      "\n",
      "\n",
      "Short Bones\n",
      " —Where a part of the skeleton is intended for strength and compactness combined with\n",
      "limited movement, it is constructed of a number of short bones, as in the carpu s and tarsus\n",
      "\n",
      "#### Page 37\n",
      "1\n",
      "\n",
      "\n",
      "In the skeleton of the adult there are 206 distinct bones, as follows:— 2\n",
      "\n",
      "\n",
      "Axial\n",
      "\n",
      "Skeleton\n",
      "\n",
      "\n",
      "Vertebral column 26\n",
      "\n",
      "Skull 22\n",
      "\n",
      "Hyoid bone 1\n",
      "\n",
      "Ribs and sternum 25\n",
      "\n",
      "\n",
      "— 74\n",
      "\n",
      "Appendicular Upper extremities 64\n",
      "\n",
      "\n",
      "Skeleton\n",
      "\n",
      "\n",
      "Upper extremities 64\n",
      "\n",
      "Lower extremities 62\n",
      "\n",
      "\n",
      "— 126\n",
      "\n",
      "Auditory ossicles 6\n",
      "\n",
      "—\n",
      "\n",
      "Total 206\n",
      "\n",
      "The patellæ are included in this enumeration, but the smaller sesamoid bones are not reckoned\n",
      "\n",
      "#### Page 37\n",
      "A short perforation is called a foramen, a longer passage a canal\n",
      "\n",
      "## 1\n",
      " Development of the Skeleton\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "#### Page 38\n",
      "\n",
      "The Skeleton\n",
      " —The skeleton is of mesodermal origin, and may be divided into ( a )\n",
      "\n",
      "새 쿼리: What are the four main classes of bones?, 카테고리: 16\n",
      "가상 문서 : 8. Ensure that all sentences have proper grammar and punctuation.\n",
      "9. The first sentence should be a brief introduction to the subject matter. \"뼈는 동물의 골격을 구성하며 다양한 기능을 수행합니다. 이러한 기능에는 지지력 제공, 이동성 촉진 및 내부 장기와 기관 보호가 포함됩니다. 분류학적으로 볼 때, 뼈는 일반적으로 네 가지 주요 범주로 나뉩니다: 장기골(장기뼈), 단축골(단축뼈), 부정형골(비정형뼈) 그리고 가변골(유연뼈). 각 그룹은 고유한 특징과 구조를 가지고 있습니다.\"\n",
      "\"**장기골:** 이 유형의 뼈들은 긴 길이를 가지고 있으며 중앙에 하나의 관통하는 통로를 가진 원뿔 모양을 하고 있어 '긴장' 또는 '장거리 뼈'라고 불립니다. 인간에서 대표적인 예로는 대퇴골, 상완골, 요추 등이 있습니다. 장기골은 주로 무게를 지탱하고 관절로 이어지는 역할을 하며, 근육 부착부로서 작용하여 몸을 구동시킵니다. 이들은 외부층인 피질뼈와 내강이 있는 해면골이라는 두 층으로 이루어져 있습니다.\"\n",
      "\"**단축골:** 반대로, 단축골은 매우 작고 거의 모든 방향에서 압력을 견딜 수 있게 하는 고른 강도를 지닌 타원형을 이루며, '단축' 또는 '짧은 뼈'라고도 합니다. 인간의 경우 엄지손가락 끝부분이나 손가락 마디 같은 작은 뼈들이 이에 속합니다. 이들의 주된 목적은 손목과 발목 관절에서의 안정성을 제공하는 것입니다. 또한 그들은 힘줄과 인대의 단단한 연결점으로 작용합니다.\"\n",
      "\"**부정형골:** 정규 형태 없이 불규칙하게 형성되거나 여러 부분들로 구성된 비정상적 형태의 뼈들을 말합니다. 예를 들어, 후두나 귀 달걀막 등은 부정형골입니다. 그들의 구조는 주변\n",
      "가상 문서 생성 시간 : 94.34987831115723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160f3a672a2d4fb2930a2e447897533e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################다중 컬렉션 검색 결과 :  [{'chunk': 'In the limbs, they are of considerable length, especially the more\\nsuperficial ones; they surround the bones, and constitute an important protection to the various joints\\n In the\\ntrunk, they are broad, flattened, and expanded, and assist in forming the walls of the trunk cavities', 'score': 0.5761654376983643, 'bm25_score': 0.0, 'vector_score': 0.5761654376983643, 'memory_score': 0.5761654376983643, 'index': 0, 'page': '243', 'collection': '4_Myology'}, {'chunk': 'The bones belonging to this class are: the clavicle, humerus, radius, ulna, femur, tibia, fibula,\\nmetacarpals, metatarsals, and phalanges\\n\\n\\nShort Bones\\n —Where a part of the skeleton is intended for strength and compactness combined with\\nlimited movement, it is constructed of a number of short bones, as in the carpu s and tarsus', 'score': 0.5437202155590057, 'bm25_score': 0.0, 'vector_score': 0.5437202155590057, 'memory_score': 0.5437202155590057, 'index': 0, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'It is a long bone, prismatic in form and slightly curved longitudinally\\n It has a body\\nand two extremities\\n\\n\\nThe Upper Extremity ( proximal extremity )\\n —The upper extremity presents a head, neck, and tuberosity', 'score': 0.5380845665931702, 'bm25_score': 0.0, 'vector_score': 0.5380845665931702, 'memory_score': 0.5380845665931702, 'index': 1, 'page': '37', 'collection': '2_Osteology'}, {'chunk': '; (4) from their shape, as the\\nDeltoideus, Rhomboideus; (5) from the number of their divisions, as the Biceps and Triceps; (6) from their\\npoints of attachment, as the Sternocleidomastoideus, Sternohyoideus, Sternothyreoideus', 'score': 0.5314441323280334, 'bm25_score': 0.0, 'vector_score': 0.5314441323280334, 'memory_score': 0.5314441323280334, 'index': 1, 'page': '243', 'collection': '4_Myology'}, {'chunk': 'The proximal part consists of a series of more or less cubical bones which allow a slight amount\\nof gliding on one another and are chiefly concerned in distributing forces transmitted to or from the bones of\\nthe arm or leg', 'score': 0.5308346450328827, 'bm25_score': 0.0, 'vector_score': 0.5308346450328827, 'memory_score': 0.5308346450328827, 'index': 2, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'A short perforation is called a foramen, a longer passage a canal\\n\\n## 1\\n Development of the Skeleton\\n\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n\\n\\n#### Page 38\\n\\nThe Skeleton\\n —The skeleton is of mesodermal origin, and may be divided into ( a ) that of the trunk ( axial\\nskeleton ), comprising the vertebral column, skull, ribs, and sternum, and ( b ) that of the limbs ( appendicular\\nskeleton )', 'score': 0.5220024585723877, 'bm25_score': 0.0, 'vector_score': 0.5220024585723877, 'memory_score': 0.5220024585723877, 'index': 3, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'They are grouped under the three headings of ligaments, omenta, and mesenteries\\n\\n\\n\\n29\\n\\n30\\n\\n\\nThe ligaments will be described with their respective organs\\n 31\\n\\nThere are two omenta, the lesser and the greater', 'score': 0.5202773213386536, 'bm25_score': 0.0, 'vector_score': 0.5202773213386536, 'memory_score': 0.5202773213386536, 'index': 0, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': 'On the radial side the greater and lesser multangulars\\narticulate with the navicular, and on the ulnar side the hamate articulates with the triangular, forming gliding\\njoints\\n\\n\\n\\n7\\n\\n8\\n\\n9\\n\\n10\\n\\n11\\n\\n12\\n\\n13\\n\\n\\nThe ligaments are: volar, dorsal, ulnar and radial collateral', 'score': 0.5200217366218567, 'bm25_score': 0.0, 'vector_score': 0.5200217366218567, 'memory_score': 0.5200217366218567, 'index': 0, 'page': '174', 'collection': '3_Syndesmology'}, {'chunk': 'Below, to the extent of about 4 mm\\n these surfaces are\\nsmooth, and covered with cartilage, which is continuous with that of the ankle-joint\\n The ligaments are:\\nanterior, posterior, inferior transverse, and interosseous', 'score': 0.5190766453742981, 'bm25_score': 0.0, 'vector_score': 0.5190766453742981, 'memory_score': 0.5190766453742981, 'index': 1, 'page': '174', 'collection': '3_Syndesmology'}, {'chunk': 'Bone\\n —Bone constitutes the fundamental element of all the joints\\n In the long bones, the extremities are the\\nparts which form the articulations; they are generally somewhat enlarged; and consist of spongy cancellous\\ntissue with a thin coating of compact substance', 'score': 0.5185781121253967, 'bm25_score': 0.0, 'vector_score': 0.5185781121253967, 'memory_score': 0.5185781121253967, 'index': 2, 'page': '174', 'collection': '3_Syndesmology'}]\n",
      "검색 시간 :  0.3100864887237549\n",
      "응답 생성 시간 :  452.902060508728\n",
      "저장 시도: ./result/5월23일\n",
      "저장 완료: ./result/5월23일\n",
      "추론시간 : 547.5665447711945\n",
      "LLM 답변: 즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요 \n",
      "즐겨요\n",
      "\n",
      "새 쿼리: Where does segmentation of the fertilized ovum occur?, 카테고리: 16\n",
      "가상 문서 : 8. Your answer must clearly indicate where segmentation of the fertilized ovum occurs without using abbreviations like \"fertilized ovum\" or acronyms like \"ovum.\" Instead, write out full terms whenever possible.\n",
      "9. The title is optional but recommended. If you choose to add it, make sure that it accurately reflects the content of the document.\n",
      "Title (optional): Segmentation of the Fertilized Ovum\n",
      "The process known as embryonic cleavage or cell division refers to the rapid succession of mitotic divisions within the zygote after fertilization has occurred. These divisions result in the formation of multiple cells from the single zygote, ultimately leading to the development of differentiated tissues and organs during the early stages of development. One critical aspect of this process involves segmentation, which refers to the rearrangement of cytoplasmic material between daughter cells. In the case of mammals such as humans, segmentation primarily takes place at two distinct sites within the developing blastocyst: the animal pole and vegetal pole.\n",
      "At the animal pole, segmentation begins around the fifth cleavage stage when the newly formed four-celled embryo undergoes compaction. During this phase, the outermost cells begin to condense and form the future ectoderm layer, which will eventually give rise to structures including skin, neural tissue, and sensory organs. At the same time, inner cells elongate along their long axis, forming polar bodies that contain excess genetic material and are subsequently expelled by the growing embryo.\n",
      "Meanwhile, at the vegetal pole, segmentation also commences around the fourth cleavage stage when the eight-celled embryo reaches its maximum size before implanting into the uterine wall. Here, the inner cells divide asymmetrically, resulting in\n",
      "가상 문서 생성 시간 : 94.99833369255066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed927fe3c56a47c196ae3ed92fa009e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################다중 컬렉션 검색 결과 :  [{'chunk': '9)\\n The segmentation of the mammalian ovum may not take place in the regular\\nsequence of two, four, eight, etc\\n, since one of the two first formed cells may subdivide more rapidly than the\\nother, giving rise to a three-or a five-cell stage', 'score': 0.577071487903595, 'bm25_score': 0.0, 'vector_score': 0.577071487903595, 'memory_score': 0.577071487903595, 'index': 0, 'page': '6', 'collection': '1_Embryology'}, {'chunk': ', segmentation and differentiation of cells\\n\\nThus, the fertilized ovum undergoes repeated segmentation into a number of cells which at first closely\\nresemble one another, but are, sooner or later, differentiated into two groups: (1) somatic cells, the function\\nof which is to build up the various tissues of the body; and (2) germinal cells, which become imbedded in\\nthe sexual glands—the ovaries in the female and the testes in the male—and are destined for the\\nperpetuation of the species', 'score': 0.5754607915878296, 'bm25_score': 0.0, 'vector_score': 0.5754607915878296, 'memory_score': 0.5754607915878296, 'index': 1, 'page': '6', 'collection': '1_Embryology'}, {'chunk': '5– Diagram showing the reduction in number of the chromosomes in the process of maturation of the\\n\\novum\\n (See enlarged image)\\n\\nThis second division is also unequal, producing a large cell which constitutes the mature ovum, and a\\nsmall cell, the second polar body', 'score': 0.5752294659614563, 'bm25_score': 0.0, 'vector_score': 0.5752294659614563, 'memory_score': 0.5752294659614563, 'index': 2, 'page': '6', 'collection': '1_Embryology'}, {'chunk': 'e\\n, while the ovum is in the uterine tube\\n The segmentation nucleus exhibits the usual mitotic\\nchanges, and these are succeeded by a division of the ovum into two cells of nearly equal size\\n 5 The\\nprocess is repeated again and again, so that the two cells are succeeded by four, eight, sixteen, thirty-two,\\nand so on, with the result that a mass of cells is found within the zona striata, and to this mass the term\\nmorula is applied (Fig', 'score': 0.5650584697723389, 'bm25_score': 0.0, 'vector_score': 0.5650584697723389, 'memory_score': 0.5650584697723389, 'index': 3, 'page': '6', 'collection': '1_Embryology'}, {'chunk': 'This is followed by a cleavage or division of the whole protoplasmic mass\\nof the cell; and thus two daughter cells are formed, each containing a nucleus\\n These daughter cells are at\\nfirst smaller than the original mother cell; but they grow, and the process may be repeated in them, so that\\nmultiplication may take place rapidly', 'score': 0.5564993023872375, 'bm25_score': 0.0, 'vector_score': 0.5564993023872375, 'memory_score': 0.5564993023872375, 'index': 4, 'page': '6', 'collection': '1_Embryology'}, {'chunk': '(2) Within this first layer is\\nto be seen a number of larger polyhedral cells, with clear nuclei, arranged in two or three layers; these are\\nthe intermediate cells or spermatocytes\\n Most of these cells are in a condition of karyokinetic division, and\\nthe cells which result from this division form those of the next layer, the spermatoblasts or spermatids', 'score': 0.5438075959682465, 'bm25_score': 0.0, 'vector_score': 0.5438075959682465, 'memory_score': 0.5438075959682465, 'index': 0, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': 'e\\n, outside the body of the\\nembryo\\n Here a new type of cell, the angioblas t or vasoformative cell, is differentiated from the mesoderm\\n\\nThese cells as they divide form small, dense syncytial masses which soon join with similar masses by means\\nof fine processes to form plexuses', 'score': 0.5395470261573792, 'bm25_score': 0.0, 'vector_score': 0.5395470261573792, 'memory_score': 0.5395470261573792, 'index': 0, 'page': '333', 'collection': '5_Angiology'}, {'chunk': 'At first each segment\\ncontains a central cavity, the myocœl, but this is soon filled with a core of angular and spindle-shaped cells\\n\\nThe cells of the segment become differentiated into three groups, which form respectively the cutis-plate or\\ndermatome, the muscle-plate or myotome, and the sclerotome (Fig', 'score': 0.5390216112136841, 'bm25_score': 0.0, 'vector_score': 0.5390216112136841, 'memory_score': 0.5390216112136841, 'index': 0, 'page': '37', 'collection': '2_Osteology'}, {'chunk': ') 1\\n Outer covering\\n 1’\\n Attached border\\n 2\\n Central stroma\\n 3\\n\\n\\nPeripheral stroma\\n 4\\n Bloodvessels\\n 5\\n Vesicular follicles in their earliest stage\\n 6, 7, 8\\n More advanced\\nfollicles\\n 9\\n An almost mature follicle', 'score': 0.5298719704151154, 'bm25_score': 0.0, 'vector_score': 0.5298719704151154, 'memory_score': 0.5298719704151154, 'index': 1, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': 'Beard says: “At the\\nclose of segmentation many of the future germ cells lie in the segmentation cavity just beneath the site of the\\nfuture embryo, and there is no doubt they subsequently wander into it', 'score': 0.5274349749088287, 'bm25_score': 0.0, 'vector_score': 0.5274349749088287, 'memory_score': 0.5274349749088287, 'index': 2, 'page': '674', 'collection': '11_Splanchnology'}]\n",
      "검색 시간 :  0.32662391662597656\n",
      "응답 생성 시간 :  471.2089660167694\n",
      "저장 시도: ./result/5월23일\n",
      "저장 완료: ./result/5월23일\n",
      "추론시간 : 566.5401723384857\n",
      "LLM 답변: [Your Required Answer]\n",
      "According to page 6, the segmentation of the mammalian ovum may not take place in the regular sequence of two, four, eight, etc, since one of the two first formed cells may subdivide more rapidly than the other, giving rise to a three-or a five-cell stage. Thus, the fertilized ovum undergoes repeated segmentation into a number of cells which at first closely resemble one another, but are, sooner or later, differentiated into two groups: (1) somatic cells, the function of which is to build up the various tissues of the body; and (2) germinal cells, which become imbedded in the sexual glands—the ovaries in the female and the testes in the male—and are destined for the perpetuation of the species.\n",
      "\n",
      "[Document]\n",
      "#### Page 6\n",
      "9)\n",
      " The segmentation of the mammalian ovum may not take place in the regular\n",
      "sequence of two, four, eight, etc\n",
      ", since one of the two first formed cells may subdivide more rapidly than the\n",
      "other, giving rise to a three-or a five-cell stage\n",
      "\n",
      "#### Page 6\n",
      ", segmentation and differentiation of cells\n",
      "\n",
      "Thus, the fertilized ovum undergoes repeated segmentation into a number of cells which at first closely\n",
      "resemble one another, but are, sooner or later, differentiated into two groups: (1) somatic cells, the function\n",
      "of which is to build up the various tissues of the body; and (2) germinal cells, which become imbedded in\n",
      "the sexual glands—the ovaries in the female and the testes in the male—and are destined for the\n",
      "perpetuation of the species\n",
      "\n",
      "#### Page 6\n",
      "5– Diagram showing\n",
      "\n",
      "새 쿼리: What is the role of the notochord?, 카테고리: 16\n",
      "가상 문서 : 8. Avoid using personal pronouns such as \"I\" or \"we\".  | Hypothetical Document Content |\n",
      "---|---\n",
      "Title: The Role of the Notochord\n",
      "The notochord plays a crucial role during embryonic development by providing structural support and guidance cues for various tissues and organs. It acts as a precursor structure that gives rise to other vital components within the developing vertebrate body plan. Here we discuss its primary functions and importance throughout embryogenesis.\n",
      "\n",
      "Paragraph 1: Structural Support\n",
      "In early stages of development, the notochord serves as a central longitudinal axis along which the entire embryo develops. As a flexible rod made up of cartilage cells (chondrocytes), it provides mechanical strength and rigidity to the elongating embryo, preventing excessive bending and deformation. Additionally, this sturdy core guides proper organ positioning and spatial arrangement, ensuring appropriate morphological organization.\n",
      "\n",
      "Paragraph 2: Signaling Mechanisms\n",
      "Beyond its physical properties, the notochord also contributes significantly through signaling mechanisms during embryogenesis. Its secreted molecules, particularly Sonic hedgehog (Shh) and Wnt proteins, regulate cell proliferation, differentiation, and migration processes. These signals are critical in establishing the polarity of adjacent tissues, such as neural plate specification and floorplate formation, as well as guiding somite segmentation and muscle patterning.\n",
      "\n",
      "Conclusion\n",
      "In summary, the notochord holds fundamental roles during embryonic development as both a structural framework and a regulatory center for numerous signal transduction pathways. Its influence extends across multiple aspects of embryogenesis, shaping the developing animal's form and function. Understanding these interactions helps us appreciate the intricate interplay\n",
      "가상 문서 생성 시간 : 94.25529599189758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4709c01d5949f4801052e2527dc9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################다중 컬렉션 검색 결과 :  [{'chunk': 'Their functions probably are to modify pressure, to diminish friction, and occasionally to\\nalter the direction of a muscle pull\\n That they are not developed to meet certain physical requirements in the\\nadult is evidenced by the fact that they are present as cartilaginous nodules in the fetus, and in greater\\nnumbers than in the adult', 'score': 0.5183810132761983, 'bm25_score': 0.0, 'vector_score': 0.5183810132761983, 'memory_score': 0.5183810132761983, 'index': 0, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'This is covered by a very vascular membrane, the perichondrium, entirely\\nsimilar to the embryonic connective tissue already described as constituting the basis of membrane bone; on\\nthe inner surface of this—that is to say, on the surface in contact with the cartilage—are gathered the\\nformative cells, the osteoblasts', 'score': 0.5099905133247375, 'bm25_score': 0.0, 'vector_score': 0.5099905133247375, 'memory_score': 0.5099905133247375, 'index': 1, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'It\\npresents apertures for the passage of vessels and nerves; the umbilicus, which in the fetus exists as an\\naperture and transmits the umbilical vessels, is closed in the adult\\n\\n\\n\\n26\\n\\n27\\n\\n28\\n\\n29\\n\\n30\\n\\n31\\n\\n32\\n\\n33\\n\\n\\n\\n#### Page 283\\n\\nFIG', 'score': 0.49465274810791016, 'bm25_score': 0.0, 'vector_score': 0.49465274810791016, 'memory_score': 0.49465274810791016, 'index': 0, 'page': '243', 'collection': '4_Myology'}, {'chunk': 'In the larger ones there are also lymphatic vessels, and cells\\nwith branching processes which communicate, through the canalculi, with the branched processes of certain\\nbone cells in the substance of the bone', 'score': 0.4862626791000366, 'bm25_score': 0.0, 'vector_score': 0.4862626791000366, 'memory_score': 0.4862626791000366, 'index': 2, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'The embryo has assumed a definite form, and its cephalic and caudal extremities are\\neasily distinguished\\n The neural folds are partly united\\n The embryo is more completely separated from the\\nyolk-sac, and the paraxial mesoderm is being divided into the primitive segments (Fig', 'score': 0.485671311726247, 'bm25_score': 0.0, 'vector_score': 0.485671311726247, 'memory_score': 0.485671311726247, 'index': 0, 'page': '6', 'collection': '1_Embryology'}, {'chunk': 'The Vertebral Column\\n —The notochord (Fig\\n 19) is a temporary structure and forms a central axis, around\\nwhich the segments of the vertebral column are developed\\n 1 1 It is derived from the entoderm, and consists\\nof a rod of cells, which lies on the ventral aspect of the neural tube and reaches from the anterior end of the\\nmid-brain to the extremity of the tail', 'score': 0.48294830322265625, 'bm25_score': 0.0, 'vector_score': 0.48294830322265625, 'memory_score': 0.48294830322265625, 'index': 3, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'It transmits the medulla\\noblongata and its membranes, the accessory nerves, the vertebral arteries, the anterior and posterior spinal\\narteries, and the membrana tectoria and alar ligaments\\n\\n\\nAngles\\n —The superior angle of the occipital bone articulates with the occipital angles of the parietal bones\\nand, in the fetal skull, corresponds in position with the posterior fontanelle', 'score': 0.4793504476547241, 'bm25_score': 0.0, 'vector_score': 0.4793504476547241, 'memory_score': 0.4793504476547241, 'index': 4, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'Anatomy of the Human Body\\n 1918\\n\\n## 7\\n The Notochord\\n\\nThe notochord (Fig\\n 19) consists of a rod of cells situated on the ventral aspect of the neural tube; it\\nconstitutes the foundation of the axial skeleton, since around it the segments of the vertebral column are\\nformed', 'score': 0.47197210788726807, 'bm25_score': 0.0, 'vector_score': 0.47197210788726807, 'memory_score': 0.47197210788726807, 'index': 1, 'page': '6', 'collection': '1_Embryology'}, {'chunk': 'This organ is well-developed in many of the lower animals, where it apparently plays a part in the\\nsense of smell, since it is supplied by twigs of the olfactory nerve and lined by epithelium similar to that in\\nthe olfactory region of the nose', 'score': 0.4706106185913086, 'bm25_score': 0.0, 'vector_score': 0.4706106185913086, 'memory_score': 0.4706106185913086, 'index': 0, 'page': '623', 'collection': '10_The_Organs_of_the_Senses_and_the_Common_Integument'}, {'chunk': 'In the limbs, they are of considerable length, especially the more\\nsuperficial ones; they surround the bones, and constitute an important protection to the various joints\\n In the\\ntrunk, they are broad, flattened, and expanded, and assist in forming the walls of the trunk cavities', 'score': 0.4690392017364502, 'bm25_score': 0.0, 'vector_score': 0.4690392017364502, 'memory_score': 0.4690392017364502, 'index': 1, 'page': '243', 'collection': '4_Myology'}]\n",
      "검색 시간 :  0.3254878520965576\n",
      "응답 생성 시간 :  458.08615922927856\n",
      "저장 시도: ./result/5월23일\n",
      "저장 완료: ./result/5월23일\n",
      "추론시간 : 552.6727564334869\n",
      "LLM 답변: [Your Required Answer]\n",
      "According to page 37, the notochord plays a key role in vertebral development.\n",
      "\n",
      "[Document]\n",
      "#### Page 37\n",
      "Their functions probably are to modify pressure, to diminish friction, and occasionally to\n",
      "alter the direction of a muscle pull\n",
      " That they are not developed to meet certain physical requirements in the\n",
      "adult is evidenced by the fact that they are present as cartilaginous nodules in the fetus, and in greater\n",
      "numbers than in the adult\n",
      "\n",
      "#### Page 37\n",
      "This is covered by a very vascular membrane, the perichondrium, entirely\n",
      "similar to the embryonic connective tissue already described as constituting the basis of membrane bone; on\n",
      "the inner surface of this—that is to say, on the surface in contact with the cartilage—are gathered the\n",
      "formative cells, the osteoblasts\n",
      "\n",
      "#### Page 243\n",
      "It\n",
      "presents apertures for the passage of vessels and nerves; the umbilicus, which in the fetus exists as an\n",
      "aperture and transmits the umbilical vessels, is closed in the adult\n",
      "\n",
      "\n",
      "\n",
      "26\n",
      "\n",
      "27\n",
      "\n",
      "28\n",
      "\n",
      "29\n",
      "\n",
      "30\n",
      "\n",
      "31\n",
      "\n",
      "32\n",
      "\n",
      "33\n",
      "\n",
      "\n",
      "\n",
      "#### Page 283\n",
      "\n",
      "FIG\n",
      "\n",
      "#### Page 37\n",
      "In the larger ones there are also lymphatic vessels, and cells\n",
      "with branching processes which communicate, through the canalculi, with the branched processes of certain\n",
      "bone cells in the substance of the bone\n",
      "\n",
      "#### Page 6\n",
      "The embryo has assumed a definite form, and its cephalic and caudal extremities are\n",
      "easily distinguished\n",
      "\n",
      "새 쿼리: What are the two types of bone marrow and what are their differences?, 카테고리: 16\n",
      "가상 문서 : 8. Use proper grammar and punctuation throughout the entire response.  | **I. Introduction**                               |\n",
      "|------------------                             |\n",
      "| Bone marrow is an essential component of our skeletal system that plays a crucial role in maintaining blood cell production. It can be categorized into two main types based on its location and function. The primary difference between these types lies in their composition, structure, and purpose within the body.          |\n",
      "| II. Red Marrow (Primary/Medullary)           |\n",
      "|---------------------------------------------|\n",
      "| Red marrow is found predominantly inside long bones like femur, tibia, humerus, and vertebrae. Its name derives from the red coloration due to high concentrations of hemoglobin produced by actively dividing hematopoietic cells. These cells give rise to various blood components such as red blood cells, white blood cells, and platelets. As we age, fatty tissue tends to replace red marrow, which leads to a decrease in hematopoiesis. However, it remains active during periods of increased demand for blood cells, including inflammation and stress.         |\n",
      "| III. Yellow Marrow (Adipose/Secondary)       |\n",
      "|--------------------------------------------|\n",
      "| Conversely, yellow marrow is primarily composed of adipocytes – fat-storing cells – rather than hematopoietic stem cells. Found mainly in flat bones like ribs and scapulae, it serves as a reserve source of energy when required by the body. Although it does contain some residual hematopoietic activity, yellow marrow's main function is lipid storage. Unlike red marrow, yellow marrow remains relatively constant in size and density across different stages of life.                     |\n",
      "| IV. Summary                               |\n",
      "가상 문서 생성 시간 : 93.78686714172363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd960b4735f4438af78d42eb598f299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################다중 컬렉션 검색 결과 :  [{'chunk': 'In the flat and short bones, in the articular ends of the long bones, in the bodies of\\nthe vertebræ, in the cranial diploë, and in the sternum and ribs the marrow is of a re d color, and contains, in\\n100 parts, 75 of water, and 25 of solid matter consisting of cell-globulin, nucleoprotein, extractives, salts,\\nand only a small proportion of fat', 'score': 0.5381865501403809, 'bm25_score': 0.0, 'vector_score': 0.5381865501403809, 'memory_score': 0.5381865501403809, 'index': 0, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'It\\nis composed of two layers, an inner or meningeal and an outer or endosteal, closely connected together,\\nexcept in certain situations, where, as already described (page 654), they separate to form sinuses for the\\npassage of venous blood', 'score': 0.5157003700733185, 'bm25_score': 0.0, 'vector_score': 0.5157003700733185, 'memory_score': 0.5157003700733185, 'index': 0, 'page': '473', 'collection': '9_Neurology'}, {'chunk': 'Between the two layers of which it is composed are contained bloodvessels, nerves, lacteals, and\\nlymph glands, together with a variable amount of fat\\n\\n\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10\\n\\n11\\n\\n12\\n\\n\\n\\n#### Page 733\\n\\nFIG', 'score': 0.5148831605911255, 'bm25_score': 0.0, 'vector_score': 0.5148831605911255, 'memory_score': 0.5148831605911255, 'index': 0, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': 'It differs in composition in different bones\\n In the bodies of the long bones\\nthe marrow is of a yello w color, and contains, in 100 parts, 96 of fat, 1 of areolar tissue and vessels, and 3 of\\nfluid with extractive matter; it consists of a basis of connective tissue supporting numerous bloodvessels and\\ncells, most of which are fat cells but some are “marrow cells,” such as occur in the red marrow to be\\nimmediately described', 'score': 0.505897581577301, 'bm25_score': 0.0, 'vector_score': 0.505897581577301, 'memory_score': 0.505897581577301, 'index': 1, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'It consists of bundles of unstriped muscular fibers,\\ndisposed in layers, intermixed with areolar tissue, bloodvessels, lymphatic vessels, and nerves\\n The layers\\nare three in number: external, middle, and internal', 'score': 0.49757397174835205, 'bm25_score': 0.0, 'vector_score': 0.49757397174835205, 'memory_score': 0.49757397174835205, 'index': 1, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': '114 1 )\\n It consists of several layers of cells, of which the innermost—that is to say, the cells\\nin contact with the urine—are somewhat flattened, with concavities on their deep surfaces into which the\\nrounded ends of the cells of the second layer fit', 'score': 0.4917311668395996, 'bm25_score': 0.0, 'vector_score': 0.4917311668395996, 'memory_score': 0.4917311668395996, 'index': 2, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': 'It is formed medially by the pubis, above by the ilium, laterally\\nand below by the ischium; a little less than two-fifths is contributed by the ilium, a little more than two-fifths\\nby the ischium, and the remaining fifth by the pubis', 'score': 0.4897347688674927, 'bm25_score': 0.0, 'vector_score': 0.4897347688674927, 'memory_score': 0.4897347688674927, 'index': 2, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'The cells are polyhedral in shape, and each contains a large nucleus imbedded in\\nfinely granular protoplasm, which is stained yellow by chromic salts\\n Numerous nerve fibers, derived from the\\nsympathetic plexus on the carotid artery, are distributed throughout the organ, and a net-work of large\\nsinusoidal capillaries ramifies among the cells', 'score': 0.48846155405044556, 'bm25_score': 0.0, 'vector_score': 0.48846155405044556, 'memory_score': 0.48846155405044556, 'index': 3, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': 'In the adult it occasionally persists, and may assist in preventing the\\nreflux of blood into the inferior vena cava; more commonly it is small, and may present a cribriform or\\nfilamentous appearance; sometimes it is altogether wanting', 'score': 0.4884136915206909, 'bm25_score': 0.0, 'vector_score': 0.4884136915206909, 'memory_score': 0.4884136915206909, 'index': 0, 'page': '333', 'collection': '5_Angiology'}, {'chunk': 'The red marrow consists of a small quantity of connective tissue,\\nbloodvessels, and numerous cells (Fig\\n 72), some few of which are fat cells, but the great majority are\\nroundish nucleated cells, the true “marrow cells” of Kölliker', 'score': 0.4860699772834778, 'bm25_score': 0.0, 'vector_score': 0.4860699772834778, 'memory_score': 0.4860699772834778, 'index': 3, 'page': '37', 'collection': '2_Osteology'}]\n",
      "검색 시간 :  0.35122013092041016\n",
      "응답 생성 시간 :  454.94150614738464\n",
      "저장 시도: ./result/5월23일\n",
      "저장 완료: ./result/5월23일\n",
      "추론시간 : 549.085479259491\n",
      "LLM 답변: [Your Required Answer]\n",
      "According to pages 37, 674, and 733, there are two types of bone marrow: red marrow and yellow marrow. Red marrow consists of a small quantity of connective tissue, blood vessels, and numerous cells, some few of which are fat cells, but the great majority are roundish nucleated cells, the true \"marrow cells\" of Kölliker. Yellow marrow, on the other hand, contains 96% fat, 1% areolar tissue and vessels, and 3% fluid with extractive matter, and consists of a basis of connective tissue supporting numerous blood vessels and cells, most of which are fat cells but some are \"marrow cells,\" such as occur in the red marrow to be immediately described. The differences between the two types of bone marrow include their composition, with red marrow containing more cells and yellow marrow containing more fat, and their functions, with red marrow being responsible for the production of blood cells and yellow marrow serving as a storage site for fat.  \n",
      "[Document]\n",
      "#### Page 37\n",
      "In the flat and short bones, in the articular ends of the long bones, in the bodies of\n",
      "the vertebræ, in the cranial diploë, and in the sternum and ribs the marrow is of a re d color, and contains, in\n",
      "100 parts, 75 of water, and 25 of solid matter consisting of cell-globulin, nucleoprotein, extractives, salts,\n",
      "and only a small proportion of fat\n",
      "\n",
      "#### Page 473\n",
      "It\n",
      "is composed of two layers, an inner or meningeal and an outer or endosteal, closely connected together,\n",
      "except in certain situations, where, as already described (page 654),\n",
      "\n",
      "새 쿼리: What is the difference between intramembranous ossification and intracartilaginous ossification in bone formation?, 카테고리: 16\n",
      "가상 문서 : 8. Use complete sentences and proper grammar throughout.  | Bone Formation: Differences Between Intramembranous Ossification and Intracartilaginous Ossification |\n",
      "|-----------------------------------------------------------------------------|\n",
      "Intramembranous ossification (IMO) and intracartilaginous ossification (ICO) are two distinct processes involved in bone development. Both occur during embryonic stages; however, they differ significantly in terms of their underlying mechanisms, cellular components, and end results. Understanding these differences can provide valuable insights into skeletal biology, growth disorders, and clinical applications such as regenerative medicine.\n",
      "\n",
      "**Key Terms:**\n",
      "* **Intramembranous Ossification (IMO):** The process by which bones form directly from mesenchymal cells without undergoing cartilage intermediates. It primarily occurs in flat and irregularly shaped bones like cranial vault, vertebrae, and clavicles. IMO involves direct differentiation of mesodermally derived connective tissue precursors called mesenchyme into mature osteoblasts that secrete mineralized matrix, eventually leading to bone formation. These osteoblasts then become embedded within the newly formed bone, transforming into bone lining cells and subsequently osteocytes.\n",
      "\n",
      "**Intracartilaginous Ossification (ICO):** A process whereby cartilage first forms before being converted into bone through endochondral ossification. ICO predominantly takes place in long bones like limbs, ribs, and sternum. During this process, chondrocytes residing within hypertrophic zones of developing cartilage begin producing type X collagen, which acts as a template for calcification and vascular invasion\n",
      "가상 문서 생성 시간 : 94.17154216766357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c92db21730f4863956b044184e87ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################다중 컬렉션 검색 결과 :  [{'chunk': 'Ossification\\n —Some bones are preceded by membrane, such as those forming the roof and sides of the\\nskull; others, such as the bones of the limbs, are preceded by rods of cartilage\\n Hence two kinds of\\nossification are described: the intramembranou s and the intracartilaginous', 'score': 0.6255343556404114, 'bm25_score': 0.0, 'vector_score': 0.6255343556404114, 'memory_score': 0.6255343556404114, 'index': 0, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'By the agency of these cells a thin layer of bony tissue is formed between\\nthe perichondrium and the cartilage, by the intramembranous mode of ossification just described\\n There are\\nthen, in this first stage of ossification, two processes going on simultaneously: in the center of the cartilage\\nthe formation of a number of oblong spaces, formed of calcified matrix and containing the withered cartilage\\ncells, and on the surface of the cartilage the formation of a layer of true membrane bone', 'score': 0.6107990741729736, 'bm25_score': 0.0, 'vector_score': 0.6107990741729736, 'memory_score': 0.6107990741729736, 'index': 1, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'This is covered by a very vascular membrane, the perichondrium, entirely\\nsimilar to the embryonic connective tissue already described as constituting the basis of membrane bone; on\\nthe inner surface of this—that is to say, on the surface in contact with the cartilage—are gathered the\\nformative cells, the osteoblasts', 'score': 0.6008042693138123, 'bm25_score': 0.0, 'vector_score': 0.6008042693138123, 'memory_score': 0.6008042693138123, 'index': 2, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'The peripheral portion is more fibrous, while, in the interior the cells\\nor osteoblasts predominate; the whole tissue is richly supplied with blood vessels\\n At the outset of the\\nprocess of bone formation a little network of spicules is noticed radiating from the point or center of\\nossification', 'score': 0.6002806723117828, 'bm25_score': 0.0, 'vector_score': 0.6002806723117828, 'memory_score': 0.6002806723117828, 'index': 3, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'The second stage\\nconsists in the prolongation into the cartilage of processes of the deeper or osteogenetic layer of the\\nperichondrium, which has now become periosteum (Fig\\n 79, ir )\\n The processes consist of bloodvessels and\\ncells— osteoblasts, or bone-formers, and osteoclasts, or bone-destroyers', 'score': 0.5908299386501312, 'bm25_score': 0.0, 'vector_score': 0.5908299386501312, 'memory_score': 0.5908299386501312, 'index': 4, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'In this osteoblasts make their appearance, and the process\\nof ossification goes on in identically the same manner as in the ordinary intramembranous ossification of\\nbone\\n In this way the cement is formed, and consists of ordinary bone containing canaliculi and lacunæ', 'score': 0.563232034444809, 'bm25_score': 0.0, 'vector_score': 0.563232034444809, 'memory_score': 0.563232034444809, 'index': 0, 'page': '674', 'collection': '11_Splanchnology'}, {'chunk': 'During the process of development many of the\\ncells of the mesoderm are differentiated into bones, muscles, vessels, etc\\n; the cells of the mesoderm which\\nare not so utilized form an investment for these structures and are differentiated into the true skin and the\\nfasciæ of the body', 'score': 0.5275056660175323, 'bm25_score': 0.0, 'vector_score': 0.5275056660175323, 'memory_score': 0.5275056660175323, 'index': 0, 'page': '243', 'collection': '4_Myology'}, {'chunk': 'Thus continuous cores of mesoderm form the axes of the\\nlimb-buds and a continuous column of mesoderm the future vertebral column\\n The first indications of the\\nbones and joints are circumscribed condensations of the mesoderm; these condensed parts become\\nchondrified and finally ossified to form the bones of the skeleton', 'score': 0.5135995447635651, 'bm25_score': 0.0, 'vector_score': 0.5135995447635651, 'memory_score': 0.5135995447635651, 'index': 0, 'page': '174', 'collection': '3_Syndesmology'}, {'chunk': 'The malleus, with the exception of its anterior process is\\nossified from a single center which appears near the neck of the bone; the anterior process is ossified\\nseparately in membrane and joins the main part of the bone about the sixth month of fetal life', 'score': 0.5099761486053467, 'bm25_score': 0.0, 'vector_score': 0.5099761486053467, 'memory_score': 0.5099761486053467, 'index': 0, 'page': '623', 'collection': '10_The_Organs_of_the_Senses_and_the_Common_Integument'}, {'chunk': 'The intervening non-condensed portions\\nconsist at first of undifferentiated mesoderm, which may develop in one of three directions\\n It may be\\nconverted into fibrous tissue as in the case of the skull bones, a synarthrodial joint being the result, or it may\\nbecome partly cartilaginous, in which case an amphiarthrodial joint is formed', 'score': 0.5034218728542328, 'bm25_score': 0.0, 'vector_score': 0.5034218728542328, 'memory_score': 0.5034218728542328, 'index': 1, 'page': '174', 'collection': '3_Syndesmology'}]\n",
      "검색 시간 :  0.3154141902923584\n",
      "응답 생성 시간 :  468.91126704216003\n",
      "저장 시도: ./result/5월23일\n",
      "저장 완료: ./result/5월23일\n",
      "추론시간 : 563.4052436351776\n",
      "LLM 답변: [Your Required Answer]\n",
      "According to page 37, intramembranous ossification involves the formation of a thin layer of bony tissue between the perichondrium and the cartilage, while intracartilaginous ossification involves the formation of a layer of true membrane bone on the surface of the cartilage. Intramembranous ossification is characterized by the formation of a number of oblong spaces filled with calcified matrix and containing the withered cartilage cells, while intracartilaginous ossification involves the formation of a layer of true membrane bone on the surface of the cartilage. The two processes occur simultaneously during the first stage of ossification, with the formation of a layer of true membrane bone on the surface of the cartilage and the formation of a number of oblong spaces filled with calcified matrix and containing the withered cartilage cells in the center of the cartilage. In the second stage of ossification, processes of the deeper or osteogenetic layer of the perichondrium, which has now become periosteum, extend into the cartilage, and the process of ossification goes on in the same manner as in the ordinary intramembranous ossification of bone.  \n",
      "[Document]\n",
      "#### Page 37\n",
      "Ossification\n",
      " —Some bones are preceded by membrane, such as those forming the roof and sides of the\n",
      "skull; others, such as the bones of the limbs, are preceded by rods of cartilage\n",
      " Hence two kinds of\n",
      "ossification are described: the intramembranous and the intracartilaginous\n",
      "\n",
      "#### Page 37\n",
      "By the agency of these cells a thin layer of bony tissue is formed between\n",
      "the per\n",
      "\n",
      "새 쿼리: What are the structural components that make up a typical vertebra?, 카테고리: 16\n",
      "가상 문서 : 8. Format citations using APA format if necessary (author last name & year).\n",
      "9. Use descriptive titles/headers for sections when appropriate.\n",
      "10. Use simple language suitable for general audiences.  | Vertebral Column | Structural Components | Description                              |\n",
      "|---|---|-------------------------------|----------------------------------------|\n",
      "| **Vertebrae**      | Body        | The main component of the vertebra; it houses spinal nerves and provides support.                    |\n",
      "|                  | Arch          | Curved structure above the body providing stability and attachment points for muscles.            |\n",
      "|                  | Spinous Process | Projecting spine-shaped bone at the top of the arch; serves as attachment point for ligaments.     |\n",
      "|                  | Transverse Process | Horizontal projection from sides of the arch, attaching ribs and other muscles.                  |\n",
      "|                  | Articular Process | Two pairs of bony projections below the body, allowing adjacent vertebrae to articulate.        |\n",
      "|                  | Pedicle        | Wide, flat bones connecting the arch and the body; they form part of the neural canal.                |\n",
      "|                  | Lamina          | Flat bones forming roof of the neural canal; one pair anteriorly, two posteriorly.                  |\n",
      "|                  | Facet             | Flattened articular surfaces on laminae, permitting facet joint formation between vertebrae.   |\n",
      "| **Intervertebral Disc** | Nucleus Pulposus | Central gelatinous core surrounded by fibrous rings called annulus fibrosus.                  |\n",
      "|                      | Annulus Fibrosus | Strong outer ring composed of collagen fibers, protecting nucleus pulposus and absorbing shock. |\n",
      "|\n",
      "가상 문서 생성 시간 : 95.11489415168762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0481cefa085246708335332b963a3bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################다중 컬렉션 검색 결과 :  [{'chunk': 'The body is like that of a cervical\\nvertebra, being broad transversely; its upper surface is concave, and lipped on either side\\n The superior\\narticular surface s are directed upward and backward; the spinous process is thick, long, and almost\\nhorizontal', 'score': 0.5560210347175598, 'bm25_score': 0.0, 'vector_score': 0.5560210347175598, 'memory_score': 0.5560210347175598, 'index': 0, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'The superior articular processes\\nare thin plates of bone projecting upward from the junctions of the pedicles and laminæ; their articular facets\\nare practically flat, and are directed backward and a little lateralward and upward', 'score': 0.5358022451400757, 'bm25_score': 0.0, 'vector_score': 0.5358022451400757, 'memory_score': 0.5358022451400757, 'index': 1, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'In front, it is in\\nrelation with the Psoas major; behind, with the muscles occupying the vertebral groove; above, with the\\nQuadratus lumborum\\n\\n\\nCONTENTS · BIBLIOGRAPHIC RECORD          - ILLUSTRATIONS · SUBJECT INDEX\\n\\nPREVIOUS NEXT\\n\\nSearch Amazon:\\n\\nC li c k h e r e to sh op th e B a r t l eby B oo k sto r e', 'score': 0.5345678329467773, 'bm25_score': 0.0, 'vector_score': 0.5345678329467773, 'memory_score': 0.5345678329467773, 'index': 0, 'page': '174', 'collection': '3_Syndesmology'}, {'chunk': 'The\\narticular surfaces are connected together by a capsule, which is thickened medially and laterally, and, to a\\nless extent, in front and behind\\n These thickened portions are usually described as distinct ligaments under\\nthe following names:\\n\\nThe Anterior', 'score': 0.5320689678192139, 'bm25_score': 0.0, 'vector_score': 0.5320689678192139, 'memory_score': 0.5320689678192139, 'index': 1, 'page': '174', 'collection': '3_Syndesmology'}, {'chunk': 'The superio r or proximal, and inferior\\nor distal surfaces are articular, the superior generally convex, the inferior concave; the media l and lateral\\nsurface s are also articular where they are in contact with contiguous bones, otherwise they are rough and\\ntuberculated', 'score': 0.5286183953285217, 'bm25_score': 0.0, 'vector_score': 0.5286183953285217, 'memory_score': 0.5286183953285217, 'index': 2, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'The superio r and inferior articular processes on\\neither side are fused to form an articular pillar, which projects lateralward from the junction of the pedicle and\\nlamina\\n The articular facets are flat and of an oval form: the superior look backward, upward, and slightly\\nmedialward: the inferior forward, downward, and slightly lateralward', 'score': 0.5285888314247131, 'bm25_score': 0.0, 'vector_score': 0.5285888314247131, 'memory_score': 0.5285888314247131, 'index': 3, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'The bone has a body and two extremities\\n\\n\\nThe Upper Extremity or Head ( capitulum fibulœ; proximal extremity )\\n —The upper extremity is of an\\nirregular quadrate form, presenting above a flattened articular surface, directed upward, forward, and\\nmedialward, for articulation with a corresponding surface on the lateral condyle of the tibia', 'score': 0.5267337560653687, 'bm25_score': 0.0, 'vector_score': 0.5267337560653687, 'memory_score': 0.5267337560653687, 'index': 4, 'page': '37', 'collection': '2_Osteology'}, {'chunk': 'In the limbs, they are of considerable length, especially the more\\nsuperficial ones; they surround the bones, and constitute an important protection to the various joints\\n In the\\ntrunk, they are broad, flattened, and expanded, and assist in forming the walls of the trunk cavities', 'score': 0.5256365835666656, 'bm25_score': 0.0, 'vector_score': 0.5256365835666656, 'memory_score': 0.5256365835666656, 'index': 0, 'page': '243', 'collection': '4_Myology'}, {'chunk': 'Externally is a\\nthick layer of connective tissue, arranged in longitudinal bundles, forming a more open texture and\\ncorresponding to the reticular part of the corium; in this are contained the bloodvessels and nerves', 'score': 0.5188326015872475, 'bm25_score': 0.0, 'vector_score': 0.5188326015872475, 'memory_score': 0.5188326015872475, 'index': 0, 'page': '623', 'collection': '10_The_Organs_of_the_Senses_and_the_Common_Integument'}, {'chunk': 'Medially, it is attached by\\na series of arched processes to the intervertebral fibrocartilages, and prominent margins of the bodies of the\\nvertebræ, and to the upper part of the sacrum; the intervals left, opposite the constricted portions of the\\nbodies, transmit the lumbar arteries and veins and filaments of the sympathetic trunk', 'score': 0.5170215368270874, 'bm25_score': 0.0, 'vector_score': 0.5170215368270874, 'memory_score': 0.5170215368270874, 'index': 1, 'page': '243', 'collection': '4_Myology'}]\n",
      "검색 시간 :  0.35433077812194824\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from model_loader.config import *\n",
    "import chromadb\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "questions = [\n",
    "    \"How many bones make up the adult human skeleton?\",\n",
    "    \"What are the four main classes of bones?\",\n",
    "    \"Where does segmentation of the fertilized ovum occur?\",\n",
    "    \"What is the role of the notochord?\",\n",
    "    \"What are the two types of bone marrow and what are their differences?\",\n",
    "    \"What is the difference between intramembranous ossification and intracartilaginous ossification in bone formation?\",\n",
    "    \"What are the structural components that make up a typical vertebra?\",\n",
    "    \"What constitutes the fetal and maternal portions of the placenta?\",\n",
    "    \"What major changes are observed in the embryo during the fourth week of development?\",\n",
    "    \"How are the neural folds and neural tube formed during human embryonic development?\",\n",
    "    \"Where does the abdominal aorta begin and end?\",\n",
    "    \"How many valves are in the femoral vein?\",\n",
    "    \"What are the main tributaries of the portal vein?\",\n",
    "    \"Where do the pulmonary veins begin and where do they end?\",\n",
    "    \"How long is the superior vena cava and where does it begin?\",\n",
    "    \"What are the main tributaries of the coronary sinus of the heart?\",\n",
    "    \"How are the branches of the abdominal aorta classified?\",\n",
    "    \"Where does the external jugular vein begin and where does it end?\",\n",
    "    \"What are the different types of external cerebral veins?\",\n",
    "    \"What are the superficial veins of the lower extremity?\",\n",
    "    \"What are the main functions of the mammary glands and where are they located in the human body?\",\n",
    "    \"How is the thyroid gland structured and what are its main anatomical relationships?\",\n",
    "    \"What are the parathyroid glands and how do they differ from the thyroid gland in structure and function?\",\n",
    "    \"Describe the structure and function of the thymus gland and how it changes throughout life.\",\n",
    "    \"What is the hypophysis cerebri (pituitary body) and how is it structured?\",\n",
    "    \"What is the pineal body, how is it structured, and what is its potential function?\",\n",
    "    \"How are the suprarenal glands structured and what are their main relationships to surrounding structures?\",\n",
    "    \"Describe the structure and function of the spleen and its relationships to surrounding organs.\",\n",
    "    \"How is the surface anatomy of the head and neck organized, particularly regarding the bony landmarks?\",\n",
    "    \"What are the surface markings of the abdomen and how are they used to locate underlying structures?\"\n",
    "]\n",
    "category_list = [\"16\"] * 30\n",
    "\n",
    "\n",
    "\n",
    "generation_loader = generation_loader\n",
    "# result_base_path = \"../result\"\n",
    "qa_system = CarManualQA(\n",
    "        generation_loader=generation_loader,\n",
    "        data_folder=\"./data\",\n",
    "        prompt_path_en=\"./prompts/en/generation/gemma3/generation_prompt3.txt\",\n",
    "        result_path=\"./result/5월16일/en-gemma3\",\n",
    "        use_vector_db=True,\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        collection_name=\"Gray\",  # 기본 컬렉션은 유지하되, 다중 검색에서는 무시됨\n",
    "        language=\"en\"\n",
    "    )\n",
    "    \n",
    "alpha_values = [round(i * 0.1, 1) for i in range(7, 11)]\n",
    "for alpha in alpha_values :\n",
    "    # alpha_result_path = f\"./result/5월23일/en-gemma3/HyDE_mean_split/alpha_{alpha}\"\n",
    "    alpha_result_path = f\"./result/5월23일\"\n",
    "    os.makedirs(alpha_result_path, exist_ok=True)\n",
    "\n",
    "    qa_system.result_path = alpha_result_path\n",
    "\n",
    "    print(f\"\\n======================Alpha 값 : {alpha}======================\")\n",
    "\n",
    "    for idx, (q, c) in enumerate(zip(questions, category_list)):\n",
    "        print(f\"\\n새 쿼리: {q}, 카테고리: {c}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        chroma_response = qa_system.generate_response(q, c, top_n=5, alpha=alpha, target_language=\"en\", idx=idx+1)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"추론시간 : {elapsed_time}\")\n",
    "        print(f\"LLM 답변: {chroma_response['후처리']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae8258",
   "metadata": {},
   "source": [
    "# 카테고리별 분할(ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬렉션 로드 중 오류 발생: Collection 1_Embryology does not exist.\n",
      "새 컬렉션 '1_Embryology'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/1_Embryology.md\n",
      "1_Embryology : 360 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 2_Osteology does not exist.\n",
      "새 컬렉션 '2_Osteology'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/2_Osteology.md\n",
      "2_Osteology : 1912 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 3_Syndesmology does not exist.\n",
      "새 컬렉션 '3_Syndesmology'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/3_Syndesmology.md\n",
      "3_Syndesmology : 902 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 4_Myology does not exist.\n",
      "새 컬렉션 '4_Myology'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/4_Myology.md\n",
      "4_Myology : 1416 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 5_Angiology does not exist.\n",
      "새 컬렉션 '5_Angiology'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/5_Angiology.md\n",
      "5_Angiology : 458 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 6_The_Arteries does not exist.\n",
      "새 컬렉션 '6_The_Arteries'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/6_The_Arteries.md\n",
      "6_The_Arteries : 1015 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 7_The_Veins does not exist.\n",
      "새 컬렉션 '7_The_Veins'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/7_The_Veins.md\n",
      "7_The_Veins : 362 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 8_The_Lymphatic_System does not exist.\n",
      "새 컬렉션 '8_The_Lymphatic_System'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/8_The_Lymphatic_System.md\n",
      "8_The_Lymphatic_System : 307 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 9_Neurology does not exist.\n",
      "새 컬렉션 '9_Neurology'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/9_Neurology.md\n",
      "9_Neurology : 2458 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 10_The_Organs_of_the_Senses_and_the_Common_Integument does not exist.\n",
      "새 컬렉션 '10_The_Organs_of_the_Senses_and_the_Common_Integument'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/10_The_Organs_of_the_Senses_and_the_Common_Integument.md\n",
      "10_The_Organs_of_the_Senses_and_the_Common_Integument : 783 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 11_Splanchnology does not exist.\n",
      "새 컬렉션 '11_Splanchnology'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/11_Splanchnology.md\n",
      "11_Splanchnology : 2137 chunks 로드 완료\n",
      "컬렉션 로드 중 오류 발생: Collection 12_Surface_Anatomy_and_Surface_Markings does not exist.\n",
      "새 컬렉션 '12_Surface_Anatomy_and_Surface_Markings'을 생성합니다.\n",
      "로드 및 캐시 저장 완료: ./data/split_file/anatomy/12_Surface_Anatomy_and_Surface_Markings.md\n",
      "12_Surface_Anatomy_and_Surface_Markings : 531 chunks 로드 완료\n"
     ]
    }
   ],
   "source": [
    "collections = [\"1_Embryology\", \"2_Osteology\", \"3_Syndesmology\", \"4_Myology\", \"5_Angiology\", \"6_The_Arteries\", \"7_The_Veins\", \"8_The_Lymphatic_System\", \"9_Neurology\", \"10_The_Organs_of_the_Senses_and_the_Common_Integument\", \"11_Splanchnology\", \"12_Surface_Anatomy_and_Surface_Markings\"]\n",
    "\n",
    "for i, collection_name in enumerate(collections) :\n",
    "    file_path = f\"./data/split_file/anatomy/{collection_name}.md\"\n",
    "\n",
    "    qa_system = CarManualQA(\n",
    "        generation_loader=generation_loader,\n",
    "        data_folder=\"./data\",\n",
    "        prompt_path_en=\"./prompts/en/generation/gemma3/generation_prompt3.txt\",\n",
    "        result_path=\"./result/5월22일/en-gemma3\",\n",
    "        use_vector_db=True,\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        collection_name=collection_name,\n",
    "        language=\"en\"\n",
    "    )\n",
    "\n",
    "    num_chunks = qa_system._load_document(file_path)\n",
    "    print(f\"{collection_name} : {num_chunks} chunks 로드 완료\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sangwon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
