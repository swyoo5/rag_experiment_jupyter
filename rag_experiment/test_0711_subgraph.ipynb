{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13bd5104",
   "metadata": {},
   "source": [
    "# subgraph 검색 로직\n",
    "\n",
    "* 키워드 위주가 아닌 서브그래프 구조 자체를 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc1fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51369a11eab44650b35584f7df53efbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: What are the two essential components of a higher organism cell as defined in the text?\n",
      "==============================\n",
      "답변: A cell in higher organisms is defined as having two essentials: cytoplasm, a soft jelly-like material, and a nucleus, a small spherical body imbedded in it (Page 6).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: Describe the four main phases of indirect cell division (karyokinesis) as outlined in the text.\n",
      "==============================\n",
      "답변: The provided text does not outline the four main phases of indirect cell division (karyokinesis). However, it does describe the initial stages of ovum segmentation. The segmentation nucleus exhibits mitotic changes and divides into two cells of nearly equal size (Page 13). These cells are then succeeded by four, eight, sixteen, thirty-two, and so on, forming a mass of cells called the morula (Page 13). Additionally, the text mentions that segmentation may not always follow a regular sequence of two, four, eight, etc., and can sometimes result in three- or five-cell stages (Page 13). \n",
      "\n",
      "It also states that each primitive germ cell divides repeatedly to create oögonia, which then develop into ova or primary oöcytes (Page 8).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What is the primary role of the yolk-sac in the embryo's early development?\n",
      "==============================\n",
      "답변: The yolk-sac is responsible for absorbing nutritive material and conveying it to the embryo via the vitelline circulation(page 20). A small part of the yolk-sac is enclosed within the embryo and constitutes the primitive digestive tube(page 19).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: How does the embryo separate from the yolk-sac, and what does the enclosed part of the yolk-sac form?\n",
      "==============================\n",
      "답변: The embryo increases in size, but the circumference of the embryonic disk grows slowly, forming a constriction between the embryo and the yolk-sac(page 19). This constriction encloses a small part of the yolk-sac within the embryo, which constitutes the primitive digestive tube(page 19).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What significant developments occur in a human embryo during the Second Week?\n",
      "==============================\n",
      "답변: I am answering based on the graph structure alone, as the provided context does not contain information about developments during the Second Week of human embryonic development. The context only mentions human embryos of about six weeks (Page 34), about eight and a half weeks old (Page 34), and from thirty-one to thirty-four days (Page 30).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What are the key characteristics of the human embryo by the end of the Third Week?\n",
      "==============================\n",
      "답변: By the end of the third week, the limbs begin to appear as small elevations or buds at the side of the trunk (Page 30).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What are the three groups into which the cells of a primitive segment differentiate, and what do they form?\n",
      "==============================\n",
      "답변: The cells of a primitive segment differentiate into three groups: the cutis-plate or dermatome, the muscle-plate or myotome, and the sclerotome (Page 38).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: How is each vertebral body formed from primitive segments during development?\n",
      "==============================\n",
      "답변: Each vertebral body is formed as a composite of two segments, originating from the posterior portion of one segment and the anterior part of the segment behind it (Page 38, 39). Specifically, the hinder part of the posterior mass joins the anterior mass of the succeeding segment to form the vertebral body (Page 38). This development is illustrated in a scheme showing how each vertebral centrum develops from portions of two adjacent segments (Page 38).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What are the sphenoidal air sinuses, and where are they located within the sphenoid bone?\n",
      "==============================\n",
      "답변: The sphenoidal air sinuses are two large cavities located within the hollowed-out interior of the sphenoid bone (Page 87). They are separated from each other by a septum (Page 87). \n",
      "\n",
      "Additionally, the sphenoidal conchæ are two thin, curved plates situated at the anterior and lower part of the body of the sphenoid (Page 89). An aperture in the anterior wall of each allows the sphenoidal sinus to open into the nasal cavity (Page 89). These sinuses are initially present as small cavities at birth but reach full size after puberty (Page 90).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: Describe the sphenoidal rostrum and its articulation.\n",
      "==============================\n",
      "답변: Schindylesis is a form of articulation where a thin plate of bone is received into a cleft formed by the separation of two laminæ in another bone, and this describes the articulation of the sphenoidal rostrum with the perpendicular plate of the ethmoid and the vomer (Page 178). The posterior border of a structure articulates with the sphenoidal crest and the vomer (Page 91).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What is the tibia, and where is it located in the human leg?\n",
      "==============================\n",
      "답변: The tibia is also known as the shin bone (Page 158). It is located in the human leg and its upper extremity is positioned toward the back of the head of the tibia, below the level of the knee-joint (Page 161). It is thick and dense in the upper and anterior part of the leg (Page 321). The Tibialis anterior is situated on the lateral side of the tibia (Page 321). It is attached medially to the tibia (Page 326).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: Describe the superior articular surface of the tibia's upper extremity.\n",
      "==============================\n",
      "답변: The upper extremity of the tibia presents a flattened articular surface, directed upward, forward, and medialward, for articulation with a corresponding surface on the lateral condyle of the tibia (Page 161). Its upper extremity is small and placed toward the back of the head of the tibia, below the level of the knee-joint (Page 161). The articular capsule is attached to the borders of the articular surfaces of the tibia and malleoli, and below to the talus around its upper articular surface (Page 232). The anterior part of the capsule is attached above to the anterior margin of the lower end of the tibia (Page 232). It is also attached to the margin of the articular surface of the tibia, blending with the transverse ligament (Page 232).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What are joints or articulations, and how are immovable joints characterized?\n",
      "==============================\n",
      "답변: Joints or articulations are formed by the reception of the head of the femur into the cup-shaped cavity of the acetabulum, creating a ball-and-socket joint (Page 222). Arthrodia are joints that admit of only gliding movement, formed by the apposition of plane surfaces (Page 179). Immovable joints, also known as synarthrodial articulations, are characterized by a direct union of cartilage, as seen with the first rib and sternum (Page 193).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: How does the articular lamella differ from ordinary bone tissue?\n",
      "==============================\n",
      "답변: The context does not contain information about articular lamella. However, it does describe two kinds of bone tissue: compact tissue, which is dense like ivory, and cancellous tissue, which consists of slender fibers and lamellæ resembling lattice-work (Page 41). It also mentions articular eminences and depressions (Page 37), but does not detail how they differ from other bone tissue. Therefore, I am answering based on the graph structure alone and can only state the two types of bone tissue described: compact and cancellous (Page 41).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: Where is the synovial membrane located in relation to the glenoid cavity and humerus, and how does it interact with the Biceps brachii tendon?\n",
      "==============================\n",
      "답변: The synovial membrane is reflected from the margin of the glenoid cavity over the labrum, and then over the inner surface of the capsule, covering the lower part and sides of the anatomical neck of the humerus as far as the articular cartilage on the head of the bone (Page 207). The tendon of the long head of the Biceps brachii passes through the capsule and is enclosed in a tubular sheath of synovial membrane, which is reflected upon it from the summit of the glenoid cavity and is continued around the tendon into the intertubercular groove as far as the surgical neck of the humerus (Page 207).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: List some of the bursae located near the shoulder-joint and specify which ones communicate with the synovial cavity.\n",
      "==============================\n",
      "답변: The upper part of the structure is covered with a thin layer of cartilage, lined by a prolongation of the synovial membrane of the shoulder-joint (page 128). A branch of the anterior humeral circumflex artery transmits to the shoulder-joint (page 128). \n",
      "\n",
      "The provided text does not list specific bursae near the shoulder-joint, only mentioning the synovial membrane and artery related to it. Therefore, I cannot list bursae or specify communication with the synovial cavity based on the given context.\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What is the function of the plantar calcaneonavicular ligament, and what condition results if it yields?\n",
      "==============================\n",
      "답변: The plantar calcaneonavicular ligament supports the head of the talus and maintains the arch of the foot (Page 236). It connects the anterior margin of the sustentaculum tali of the calcaneus to the plantar surface of the navicular (Page 235). If the joint between the talus and navicular yields, it is due to overpressure, but this portion is braced by the plantar calcaneonavicular ligament (Page 242).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: How are the navicular bone and the three cuneiform bones connected, and what type of movement do they permit?\n",
      "==============================\n",
      "답변: The navicular is connected to the three cuneiform bones by dorsal and plantar ligaments (Page 236). Mere gliding movements are permitted between the navicular and cuneiform bones (Page 236).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: How does the nervous system serve as an indicator for the origin and migration paths of developing muscles, despite not influencing muscle differentiation?\n",
      "==============================\n",
      "답변: The context states that nerves adapt to the growth and changes in the form of the central nervous system (Page 348). While the provided text does not directly address how the nervous system indicates the origin and migration paths of developing muscles *without* influencing muscle differentiation, it highlights the nervous system’s adaptability during development (Page 348). The text also mentions that different portions of muscles like the Pectoralis major, Deltoid, and Trapezius are controlled and stimulated by nerve impulses at different times (Page 244). \n",
      "\n",
      "I am answering based on the graph structure alone, as the provided context doesn't contain information to directly answer the question.\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: Describe the structural components of striped or voluntary muscle, from bundles to individual fibers.\n",
      "==============================\n",
      "답변: Striped muscle contains abundant capillaries that form a rectangular network with longitudinal branches running in the endomysium between the muscular fibers, connected by transverse anastomosing branches (Page 251). Nerves are profusely distributed throughout striped muscle (Page 251). Lymphatic vessels have not been definitively found within striped muscle itself, though they are present in tendons and muscle sheaths (Page 251). Additionally, the muscle contains osteogenetic fibers, which are made up of fine fibrils similar to those in white fibrous tissue (Page 44).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What is the triangular ligament and where is it located?\n",
      "==============================\n",
      "답변: The ulnar collateral ligament is attached to the medial side of the triangular bone (Page 214). It is located between the navicular and triangular bones in the center of the proximal row of the carpus (Page 136). Additionally, the triangular bone is connected to the hamate by a collateral ligament (Page 215), and is also connected to the lunate by a dorsal ligament (Page 215).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What structures perforate the superficial layer (inferior fascia) of the urogenital diaphragm?\n",
      "==============================\n",
      "답변: The deep dorsal vein of the clitoris, a portion of the urethra and the Constrictor urethra muscle, the larger vestibular glands and their ducts, the internal pudendal vessels and the dorsal nerves of the clitoris, and the arteries and nerves of the bulbi vestibuli, and a plexus of veins perforate the superficial layer (inferior fascia) of the urogenital diaphragm (Page 291).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: Where does the Extensor digitorum longus muscle originate, and what structures are located between it and the Tibialis anterior?\n",
      "==============================\n",
      "답변: The Extensor digitorum longus originates from the anterior surface of the fibula for about the middle two-fourths of its extent, medial to the origin of the Extensor digitorum longus, and also from the interosseous membrane to a similar extent (page 321). The Extensor hallucis longus is located between the Tibialis anterior and the Extensor digitorum longus (page 321, 159).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What is the Peronæus tertius, and where is it inserted?\n",
      "==============================\n",
      "답변: The Peronæus tertius flexes the foot, and it does so in conjunction with the Tibialis anterior (Page 325). The provided text does not state where the Peronæus tertius is inserted (Page 325).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What are the main characteristics of the middle coat (tunica media) of arteries, and how does its composition vary with vessel size?\n",
      "==============================\n",
      "답변: The arteries are composed of three coats: an internal or endothelial coat (tunica intima), a middle or muscular coat (tunica media), and an external or connective-tissue coat (tunica adventitia) (Page 333). The middle coat (tunica media) is distinguished from the inner coat by its color and the transverse arrangement of its fibers (Page 334). \n",
      "\n",
      "In the largest arteries, like the aorta and innominate, the middle coat contains a considerable amount of elastic tissue, with a few bundles of white connective tissue also present (Page 334). Some arteries, particularly those in the cranial and vertebral cavities, have extremely thin walls due to the thinness of their external and middle coats (Page 334).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: Describe the composition and variations of the external coat (tunica adventitia) in arteries.\n",
      "==============================\n",
      "답변: The external coat (tunica adventitia) consists mainly of fine and closely felted bundles of white connective tissue, but also contains elastic fibers in all but the smallest arteries (Page 334). In the largest vessels, the external coat is relatively thin, but in small arteries it is of greater proportionate thickness (Page 334). \n",
      "\n",
      "In smaller arteries, it consists of a single layer of white connective tissue and elastic fibers (Page 334). As it approaches the capillaries, the elastic fibers are wanting, and the connective tissue becomes more homogeneous and is gradually reduced to a thin membranous envelope, which eventually disappears (Page 334). The external coat also strengthens the attachment of the artery to its fibrous ring, along with the serous membrane externally and the endocardium internally (Page 356).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: How do the Vitelline Veins develop into parts of the portal and hepatic veins?\n",
      "==============================\n",
      "답변: The vitelline veins ultimately drain blood from the digestive tube and are modified to form the portal vein (Page 340). The branches conveying blood to the plexus are named the venæ advehentes, and become the branches of the portal vein (Page 345). The venæ revehentes drain the plexus into the sinus venosus and form the future hepatic veins (Page 345).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What happens to the Umbilical Veins during embryonic development and after birth?\n",
      "==============================\n",
      "답변: During embryonic development, the umbilical veins carry blood to the villi and then return it to the embryo after circulating through the capillaries of the villi (Page 24). They also undergo interruption in the developing liver, with blood passing through the liver before reaching the heart (Page 340). After birth, the umbilical veins atrophy and obliterate, forming the ligamentum teres (Page 345).\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What are the three phases of a cardiac cycle and what happens during each?\n",
      "==============================\n",
      "답변: The provided text does not contain information about the phases of a cardiac cycle. Therefore, I cannot answer your question based on the given context. I am answering based on the graph structure alone.\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "질문: What are the main peculiarities observed in the fetal heart's vascular system?\n",
      "==============================\n",
      "답변: The chorionic villi are initially small and non-vascular, consisting only of trophoblast, but they grow in size and become ramified as the mesoderm, carrying branches of the umbilical vessels, grows into them, vascularizing them (Page 24). I am answering based on the graph structure alone, as the provided text does not contain information about the fetal heart’s vascular system.\n",
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "평균 답변 시간 : 90.42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import torch\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nltk.downloader\n",
    "from datetime import datetime\n",
    "from pykeen.models import ComplEx\n",
    "from model_loader.config import *\n",
    "from pykeen.pipeline import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pykeen.triples import TriplesFactory\n",
    "from chromadb.utils import embedding_functions\n",
    "from pykeen.optimizers import AdamW as PyKeenAdamW\n",
    "from typing import List, Dict, Any, Tuple, Optional, Set\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "\n",
    "class CustomEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    def __init__(self, embedding_model):\n",
    "        self.embedding_model = embedding_model\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        return self.embedding_model.encode(texts).tolist()\n",
    "    \n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "generation_loader = generation_loader\n",
    "\n",
    "class QASystem:\n",
    "    def __init__(self, \n",
    "                 graphml_path: str, \n",
    "                 md_path: str,\n",
    "                 vector_db_path: str = \"./chroma_db_subgraph\", \n",
    "                 similarity_threshold: float = 0.5,\n",
    "                 chunk_token_threshold: int = 250,\n",
    "                 embedding_model_path: str = \"./model/embedding/bge-m3\",\n",
    "                 m_hop_depth: int=3):\n",
    "        self.graphml_path = graphml_path\n",
    "        self.md_path = md_path\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.chunk_token_threshold = chunk_token_threshold\n",
    "        self.llm_loader = None\n",
    "        self.m_hop_depth = m_hop_depth\n",
    "        \n",
    "        self.reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\")        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/ms-marco-TinyBERT-L-2-v2\")\n",
    "\n",
    "        self.embedding_model = SentenceTransformer(embedding_model_path)\n",
    "        self.custom_embedding_function = CustomEmbeddingFunction(self.embedding_model)\n",
    "\n",
    "        self.graph = nx.read_graphml(graphml_path)\n",
    "        self.node_name_map = {self._preprocess_text(node): node for node in self.graph.nodes()}\n",
    "        self.client = chromadb.PersistentClient(path=vector_db_path)\n",
    "        \n",
    "        self.entity_collection = self.client.get_or_create_collection(name=\"entities_split\", embedding_function=self.custom_embedding_function)\n",
    "        self.entity_relation_extraction_prompt_template = \"\"\"\n",
    "            Extract entities and their relations from the following sentence.\n",
    "\n",
    "            **Entities** should be **unique nouns or concepts**, extracted as **noun phrases** whenever possible. Identify **concrete objects or concepts** rather than complex activities or phenomena as entities.\n",
    "\n",
    "            **Relations** should clearly describe the connection between two entities, preferring **reusable predicate verbs** for a knowledge graph. Use **concise verbs** or clear, hyphenated forms like **'part_of' or 'includes'**.\n",
    "\n",
    "            Output the result **only in the following JSON format**, with no other explanations or text:\n",
    "\n",
    "            ```json\n",
    "            {{\n",
    "                \"entities\": [\n",
    "                    {{\"name\": \"Entity1\", \"type\": \"Type (e.g., Organ, System, Substance, Function, Disease)\"}},\n",
    "                    {{\"name\": \"Entity2\", \"type\": \"Type\"}}\n",
    "                ],\n",
    "                \"relations\": [\n",
    "                    {{\"head\": \"Entity1\", \"relation\": \"Relation_Type (e.g., part_of, causes)\", \"tail\": \"Entity2\"}},\n",
    "                    {{\"head\": \"Entity3\", \"relation\": \"generates\", \"tail\": \"Entity4\"}}\n",
    "                ]\n",
    "            }}\n",
    "\n",
    "            sentence : \"{text_to_analyze}\"\n",
    "            JSON result :\n",
    "        \"\"\"\n",
    "\n",
    "        self._initialize_vector_db()\n",
    "\n",
    "    def _preprocess_text(self, text: str) -> str:\n",
    "        return text.upper().replace(' ', '_')\n",
    "\n",
    "    def _initialize_vector_db(self):\n",
    "        if self.entity_collection.count() == 0:\n",
    "            nodes_to_add = []\n",
    "            unique_nodes = set()\n",
    "            for node, data in self.graph.nodes(data=True):\n",
    "                processed_node = self._preprocess_text(node)\n",
    "                if processed_node not in unique_nodes :\n",
    "                    metadata = {k: str(v) for k, v in data.items()}\n",
    "                    metadata['original_name'] = node\n",
    "                    nodes_to_add.append({'id': processed_node, 'document': node, 'metadata': metadata})\n",
    "                    unique_nodes.add(processed_node)\n",
    "            \n",
    "            if nodes_to_add:\n",
    "                ids = [item['id'] for item in nodes_to_add]\n",
    "                documents = [item['document'] for item in nodes_to_add]\n",
    "                metadatas = [item['metadata'] for item in nodes_to_add]\n",
    "                self.entity_collection.add(ids=ids, documents=documents, metadatas=metadatas)\n",
    "\n",
    "    def _extract_entities_relations(self, question) :\n",
    "        prompt = self.entity_relation_extraction_prompt_template.format(text_to_analyze=question)\n",
    "        raw_llm_output = self._call_llm_generate(prompt)\n",
    "\n",
    "        try :\n",
    "            json_start = raw_llm_output.find(\"{\")\n",
    "            json_end = raw_llm_output.rfind(\"}\") + 1\n",
    "            if json_start != -1 and json_end != -1 and json_end > json_start :\n",
    "                json_str = raw_llm_output[json_start:json_end]\n",
    "                extracted_data = json.loads(json_str)\n",
    "                return extracted_data.get(\"entities\", []), extracted_data.get(\"relations\", [])\n",
    "            else :\n",
    "                print(f\"LLM 답변에서 유효한 JSON 형태를 찾을 수 없음 : {raw_llm_output}\")\n",
    "                return [], []\n",
    "            \n",
    "        except json.JSONDecodeError as e :\n",
    "            print(f\"개체 추출 과정에서 JSON 디코딩 오류 발생: {e}\")\n",
    "            print(f\"오류 발생 원문: {raw_llm_output}\")\n",
    "            return [], []\n",
    "        \n",
    "    def _find_similar_nodes(self, entity_name: str, n_results: int=5) -> List[str] :\n",
    "        if not entity_name :\n",
    "            return []\n",
    "        \n",
    "        results = self.entity_collection.query(\n",
    "            query_texts=[entity_name],\n",
    "            n_results=n_results,\n",
    "            include=[\"metadatas\", \"distances\"]\n",
    "        )\n",
    "\n",
    "        candidate_nodes = []\n",
    "        if results[\"distances\"] :\n",
    "            for i, dist in enumerate(results[\"distances\"][0]) :\n",
    "                if dist <= self.similarity_threshold :\n",
    "                    candidate_nodes.append(results[\"metadatas\"][0][i][\"original_name\"])\n",
    "        return candidate_nodes\n",
    "    \n",
    "    def _find_matching_subgraph(self, query_triplets: List[Dict[str, str]]) -> List[nx.Graph]:\n",
    "        matched_subgraphs = []\n",
    "        for triplet in query_triplets:\n",
    "            head_query = triplet.get(\"head\")\n",
    "            relation_query = triplet.get(\"relation\")\n",
    "            tail_query = triplet.get(\"tail\")\n",
    "\n",
    "            if not all([head_query, relation_query, tail_query]) :\n",
    "                continue\n",
    "\n",
    "            head_candidates = self._find_similar_nodes(head_query)\n",
    "            tail_candidates = self._find_similar_nodes(tail_query)\n",
    "\n",
    "            for h_node in head_candidates:\n",
    "                for t_node in tail_candidates:\n",
    "                    if self.graph.has_edge(h_node, t_node):\n",
    "                        edge_data_list = []\n",
    "                        if self.graph.is_multigraph() :\n",
    "                            edge_data_list.extend(self.graph.get_edge_data(h_node, t_node).values())\n",
    "                        else :\n",
    "                            edge_data_list.append(self.graph.get_edge_data(h_node, t_node))\n",
    "\n",
    "                        for edge_data in edge_data_list :\n",
    "                            if isinstance(edge_data, dict) and edge_data.get(\"type\", '').lower() == relation_query.lower() :\n",
    "                                subgraph = nx.Graph()\n",
    "                                subgraph.add_node(h_node, **self.graph.nodes[h_node])\n",
    "                                subgraph.add_node(t_node, **self.graph.nodes[t_node])\n",
    "                                subgraph.add_node(h_node, t_node, **edge_data)\n",
    "                                matched_subgraphs.append(subgraph)\n",
    "\n",
    "        return matched_subgraphs\n",
    "    \n",
    "    def _retrieve_context_from_pages(self, question: str, page_numbers: Set[str], top_k: int=5) -> List[Dict] :\n",
    "        if not page_numbers:\n",
    "            return []\n",
    "\n",
    "        all_md_content = \"\"\n",
    "        for md_file in os.listdir(self.md_path):\n",
    "            if md_file.endswith(\".md\"):\n",
    "                with open(os.path.join(self.md_path, md_file), 'r', encoding='utf-8') as f:\n",
    "                    all_md_content += f.read() + \"\\n\\n\"\n",
    "\n",
    "        candidate_chunks = []\n",
    "        for page_num in page_numbers:\n",
    "            pattern = re.compile(rf\"####\\s+Page\\s+{re.escape(page_num)}\\b(.*?)(?=####\\s+Page|\\Z)\", re.S)\n",
    "            match = pattern.search(all_md_content)\n",
    "            if match:\n",
    "                page_content = match.group(1).strip()\n",
    "                try:\n",
    "                    sentences = sent_tokenize(page_content)\n",
    "                except LookupError:\n",
    "                    nltk.download('punkt')\n",
    "                    sentences = sent_tokenize(page_content)\n",
    "                \n",
    "                candidate_chunks.extend([{\"document\": s, \"metadata\": {\"source_page\": page_num}} for s in sentences])\n",
    "\n",
    "        if not candidate_chunks:\n",
    "            return []\n",
    "\n",
    "        rerank_pairs = [(question, chunk['document']) for chunk in candidate_chunks]\n",
    "        scores = self.reranker.predict(rerank_pairs)\n",
    "\n",
    "        for score, chunk in zip(scores, candidate_chunks):\n",
    "            chunk[\"rerank_score\"] = score\n",
    "\n",
    "        reranked_results = sorted(candidate_chunks, key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "        return reranked_results[:top_k]\n",
    "\n",
    "    def _retrieve_context_from_subgraphs(self, question: str, subgraphs: List[nx.Graph], top_k_rerank: int=5) -> List[Dict[str, Any]] :\n",
    "        page_numbers = set()\n",
    "        for subgraph in subgraphs :\n",
    "            for node, data in subgraph.nodes(data=True) :\n",
    "                pages_str = data.get(\"source_page\")\n",
    "                if pages_str :\n",
    "                    for page in pages_str.split(',') :\n",
    "                        if page.strip() :\n",
    "                            page_numbers.add(page.strip())\n",
    "\n",
    "        if not page_numbers :\n",
    "            return []\n",
    "        \n",
    "        all_md_content = \"\"\n",
    "        for md_file in os.listdir(self.md_path) :\n",
    "            if md_file.endswith(\".md\") :\n",
    "                with open(os.path.join(self.md_path, md_file), 'r', encoding=\"utf-8\") as f :\n",
    "                    all_md_content += f.read() + \"\\n\\n\"\n",
    "\n",
    "        candidate_chunks = []\n",
    "        for page_num in page_numbers :\n",
    "            pattern = re.compile(rf\"####\\s+Page\\s+{re.escape(page_num)}\\n(.*?)(?=####\\s+Page|\\Z)\", re.S)\n",
    "            match = pattern.search(all_md_content)\n",
    "            if match :\n",
    "                page_content = match.group(1).strip()\n",
    "                chunks = self._create_chunks_from_text(page_content, page_num)\n",
    "                candidate_chunks.extend(chunks)\n",
    "\n",
    "        if not candidate_chunks :\n",
    "            return []\n",
    "        \n",
    "        rerank_pairs = [(question, chunk[\"document\"]) for chunk in candidate_chunks]\n",
    "        scores = self.reranker.predict(rerank_pairs)\n",
    "\n",
    "        reranked_results = [{\"document\": chunk[\"document\"], \"metadata\": chunk[\"metadata\"]} for score, chunk in zip(scores, candidate_chunks)]\n",
    "\n",
    "        reranked_results.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "        return reranked_results[:top_k_rerank]\n",
    "    \n",
    "    def _create_chunks_from_text(self, text: str, page_num: str) -> List[Dict[str, Any]] :\n",
    "        chunks = []\n",
    "        paragraphs = re.split(\"\\n\\n+\", text)\n",
    "        for para in paragraphs :\n",
    "            para = para.strip()\n",
    "            if not para :\n",
    "                continue\n",
    "\n",
    "            para_tokens = self.tokenizer.tokenize(para)\n",
    "\n",
    "            if len(para_tokens) <= self.chunk_token_threshold :\n",
    "                chunks.append({\"document\": para, \"metadata\": {\"source_page\": page_num}})\n",
    "            else :\n",
    "                sentences = sent_tokenize(para)\n",
    "                current_chunk_sentences = []\n",
    "                current_chunk_tokens = 0\n",
    "\n",
    "                for sentence in sentences :\n",
    "                    sentence_tokens = self.tokenizer.tokenize(sentence)\n",
    "\n",
    "                    if current_chunk_tokens + len(sentence_tokens) > self.chunk_token_threshold and current_chunk_sentences :\n",
    "                        chunk_text = \" \".join(current_chunk_sentences)\n",
    "                        chunks.append({\"document\": chunk_text, \"metadata\": {\"source_page\": page_num}})\n",
    "                        current_chunk_sentences = [sentence]\n",
    "                        current_chunk_tokens = len(sentence_tokens)\n",
    "                    else :\n",
    "                        current_chunk_sentences.append(sentence)\n",
    "                        current_chunk_tokens += len(sentence_tokens)\n",
    "\n",
    "                if current_chunk_sentences :\n",
    "                    chunk_text = \" \".join(current_chunk_sentences)\n",
    "                    chunks.append({\"document\": chunk_text, \"metadata\": {\"source_page\": page_num}})\n",
    "\n",
    "        return chunks\n",
    "        \n",
    "    def _build_llm_prompt(self, question: str, context: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful assistant who answers questions based on the provided context.\n",
    "        You MUST cite the source page number for every piece of information you use.\n",
    "\n",
    "        **Instructions:**\n",
    "        1. Answer the user's question clearly and concisely using ONLY the provided context and knowledge graph information.\n",
    "        2. For every statement, you MUST provide the source page number in parentheses, like this: (Page XX).\n",
    "        3. If a single piece of information is supported by multiple pages, cite all of them: (Page X, Y, Z).\n",
    "        4. If no context is available, state that you are answering based on the graph structure alone.\n",
    "\n",
    "        **Example of a GOOD answer:**\n",
    "        The ductus arteriosus degenerates into the ligamentum arteriosum after birth(page 360). This is a normal physiological change that happens post-delivery(page 361).\n",
    "\n",
    "        **Example of a BAD answer:** -> (This is a bad answer because it lacks the mandatory citation)\n",
    "        The ductus arteriosus becomes the ligamentum arteriosum.\n",
    "\n",
    "        ---\n",
    "        **Context:**\n",
    "        {context}\n",
    "        ---\n",
    "        **Question:**\n",
    "        {question}\n",
    "        ---\n",
    "        **Answer:**\n",
    "        \"\"\"\n",
    "        return prompt.strip()\n",
    "    \n",
    "    def _call_llm_generate(self, prompt: str) -> str:\n",
    "        if self.llm_loader:\n",
    "            if hasattr(self.llm_loader, \"tokenizer\") and hasattr(self.llm_loader, \"model\"):\n",
    "                tokenizer = self.llm_loader.tokenizer\n",
    "                model = self.llm_loader.model\n",
    "\n",
    "                input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "                attention_mask = (input_ids != tokenizer.pad_token_id).long().to(model.device)\n",
    "\n",
    "                output = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=500,\n",
    "                    temperature=0.0,\n",
    "                    do_sample=False,\n",
    "                    top_p=0.85,\n",
    "                    repetition_penalty=1.2,\n",
    "                    early_stopping=True,\n",
    "                    num_beams=3,\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                    eos_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                generated_ids = output[0][input_ids.shape[-1]:]\n",
    "                raw_answer = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "                return raw_answer\n",
    "            else:\n",
    "                raw_answer = self.llm_loader.generate(prompt)\n",
    "                return raw_answer\n",
    "        else:\n",
    "            print(\"generation_loader가 로드되지 않음\")\n",
    "            return \"LLM 로더가 설정되지 않았습니다.\"\n",
    "        \n",
    "    def generate_response(self, question: str) -> Tuple[str, str]:\n",
    "        extracted_entities, extracted_triplets = self._extract_entities_relations(question)\n",
    "        \n",
    "        reranked_chunks = []\n",
    "        if extracted_triplets :\n",
    "            matched_subgraphs = self._find_matching_subgraph(extracted_triplets)\n",
    "            if matched_subgraphs :\n",
    "                reranked_chunks = self._retrieve_context_from_subgraphs(question, matched_subgraphs)\n",
    "\n",
    "        if not reranked_chunks and extracted_entities :\n",
    "            page_numbers = self._find_pages_from_entities(extracted_entities)\n",
    "            if page_numbers :\n",
    "                reranked_chunks = self._retrieve_context_from_pages(question, page_numbers)\n",
    "\n",
    "        if not reranked_chunks :\n",
    "            return \"관련 정보를 찾지 못했습니다\", \"\"\n",
    "        \n",
    "        final_context_parts = []\n",
    "        max_len = 3500\n",
    "        current_len = 0\n",
    "        for chunk in reranked_chunks :\n",
    "            page_num = chunk[\"metadata\"].get(\"source_page\", \"N/A\")\n",
    "            context_snippet = f\"... {chunk['document']} ... (출처 : page {page_num})\"\n",
    "            if current_len + len(context_snippet) > max_len :\n",
    "                break\n",
    "            final_context_parts.append(context_snippet)\n",
    "            current_len += len(context_snippet)\n",
    "\n",
    "        context = \"\\n\\n\".join(final_context_parts)\n",
    "        if not context :\n",
    "            return \"모델 길이 입력 제한\"\n",
    "        \n",
    "        prompt = self._build_llm_prompt(question, context)\n",
    "        answer = self._call_llm_generate(prompt)\n",
    "\n",
    "        return answer, context\n",
    "        \n",
    "    def _find_pages_from_entities(self, entities: List[Dict[str, Any]]) -> Set[str]:\n",
    "        query_texts = [e['name'] for e in entities if 'name' in e]\n",
    "        if not query_texts:\n",
    "            return set()\n",
    "\n",
    "        entity_results = self.entity_collection.query(\n",
    "            query_texts=query_texts,\n",
    "            n_results=5,\n",
    "            include=[\"metadatas\", \"distances\"]\n",
    "        )\n",
    "        # print(f\"벡터DB 검색 결과 : {entity_results.get('distances')}\")\n",
    "        # print(f\"쿼리 : {query_texts}\")\n",
    "        # print(f\"검색 결과 : {entity_results}\")\n",
    "\n",
    "        similar_entity_names = set()\n",
    "        if entity_results.get('distances'):\n",
    "            for i, dists in enumerate(entity_results['distances']):\n",
    "                for j, dist in enumerate(dists):\n",
    "                    if dist <= self.similarity_threshold:\n",
    "                        meta = entity_results['metadatas'][i][j]\n",
    "                        similar_entity_names.add(meta['original_name'])\n",
    "        \n",
    "        # print(f\"유사도 필터링 후 엔티티 : {similar_entity_names}\")\n",
    "        page_numbers = set()\n",
    "        for entity_name in similar_entity_names:\n",
    "            standarized_name = self._preprocess_text(entity_name)\n",
    "            if standarized_name in self.node_name_map :\n",
    "                original_case_node_name = self.node_name_map[standarized_name]\n",
    "                node_data = self.graph.nodes[original_case_node_name]\n",
    "                # print(f\"node_data : {node_data}\")\n",
    "                pages_str = node_data.get(\"source_page\")\n",
    "\n",
    "                # print(f\"{entity_name} 노드 데이터 : {node_data}\")\n",
    "                if pages_str :\n",
    "                    for page in pages_str.split(',') :\n",
    "                        if page.strip() :\n",
    "                            page_numbers.add(page.strip())\n",
    "            # else :\n",
    "            #     print(f\"{entity_name}을 그래프에서 찾을 수 없음\")\n",
    "        return page_numbers\n",
    "    \n",
    "    def _retrieve_and_rerank_context(self, question: str, page_numbers: Set[str], top_k_rerank: int = 5) -> List[Dict[str, Any]]:\n",
    "        if not page_numbers:\n",
    "            return []\n",
    "\n",
    "        all_md_content = \"\"\n",
    "        for md_file in os.listdir(self.md_path):\n",
    "            if md_file.endswith(\".md\"):\n",
    "                with open(os.path.join(self.md_path, md_file), 'r', encoding='utf-8') as f:\n",
    "                    all_md_content += f.read() + \"\\n\\n\"\n",
    "\n",
    "        candidate_chunks = []\n",
    "        for page_num in page_numbers:\n",
    "            pattern = re.compile(rf\"####\\s+Page\\s+{re.escape(page_num)}\\b(.*?)(?=####\\s+Page|\\Z)\", re.S)\n",
    "            match = pattern.search(all_md_content)\n",
    "            \n",
    "            if match:\n",
    "                page_content = match.group(1).strip()\n",
    "                chunks = self._create_chunks_from_text(page_content, page_num)\n",
    "                candidate_chunks.extend(chunks)\n",
    "        \n",
    "        if not candidate_chunks:\n",
    "            return []\n",
    "            \n",
    "        rerank_pairs = [(question, chunk['document']) for chunk in candidate_chunks]\n",
    "        if not rerank_pairs:\n",
    "            return []\n",
    "\n",
    "        scores = self.reranker.predict(rerank_pairs)\n",
    "\n",
    "        reranked_results = []\n",
    "        for score, chunk in zip(scores, candidate_chunks):\n",
    "            chunk[\"rerank_score\"] = score\n",
    "            reranked_results.append(chunk)\n",
    "\n",
    "        reranked_results.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "        return reranked_results[:top_k_rerank]\n",
    "\n",
    "def save_results_to_file(question: str, answer: str, context: str, output_dir: str, file_index: int):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%H%M%S_%f\")\n",
    "    file_name = f\"result_{file_index}_{timestamp}.txt\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"[질문]\\n{question}\\n\\n\")\n",
    "        f.write(f\"[답변]\\n{answer}\\n\\n\")\n",
    "        f.write(f\"[근거]\\n{context}\\n\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    qa_system = QASystem(\n",
    "        graphml_path=\"./data/knowledge_graph/knowledge_graph.graphml\",\n",
    "        md_path=\"./data/split_file/anatomy/\",\n",
    "        m_hop_depth=1\n",
    "    )\n",
    "    \n",
    "    qa_system.llm_loader = generation_loader\n",
    "    \n",
    "    questions = [\n",
    "        ############## 1_Embryology.md\n",
    "        \"What are the two essential components of a higher organism cell as defined in the text?\", # 7페이지\n",
    "        \"Describe the four main phases of indirect cell division (karyokinesis) as outlined in the text.\", # 7페이지\n",
    "        \"What is the primary role of the yolk-sac in the embryo's early development?\", # 20페이지\n",
    "        \"How does the embryo separate from the yolk-sac, and what does the enclosed part of the yolk-sac form?\", # 19페이지\n",
    "        \"What significant developments occur in a human embryo during the Second Week?\", # 33페이지\n",
    "        \"What are the key characteristics of the human embryo by the end of the Third Week?\", # 33페이지\n",
    "        \n",
    "        ############## 2_Osteology.md\n",
    "        \"What are the three groups into which the cells of a primitive segment differentiate, and what do they form?\", # 38페이지\n",
    "        \"How is each vertebral body formed from primitive segments during development?\", # 38페이지\n",
    "        \"What are the sphenoidal air sinuses, and where are they located within the sphenoid bone?\", # 88페이지\n",
    "        \"Describe the sphenoidal rostrum and its articulation.\",# 88\n",
    "        \"What is the tibia, and where is it located in the human leg?\", # 158\n",
    "        \"Describe the superior articular surface of the tibia's upper extremity.\", # 158\n",
    "\n",
    "        ############## 3_Syndesmology.md\n",
    "        \"What are joints or articulations, and how are immovable joints characterized?\", # 174\n",
    "        \"How does the articular lamella differ from ordinary bone tissue?\", # 174\n",
    "        \"Where is the synovial membrane located in relation to the glenoid cavity and humerus, and how does it interact with the Biceps brachii tendon?\", # 207\n",
    "        \"List some of the bursae located near the shoulder-joint and specify which ones communicate with the synovial cavity.\", # 207\n",
    "        \"What is the function of the plantar calcaneonavicular ligament, and what condition results if it yields?\", # 236\n",
    "        \"How are the navicular bone and the three cuneiform bones connected, and what type of movement do they permit?\", # 236\n",
    "\n",
    "        ############## 4_Myology.md\n",
    "        \"How does the nervous system serve as an indicator for the origin and migration paths of developing muscles, despite not influencing muscle differentiation?\", # 250\n",
    "        \"Describe the structural components of striped or voluntary muscle, from bundles to individual fibers.\", # 250\n",
    "        \"What is the triangular ligament and where is it located?\", # 290\n",
    "        \"What structures perforate the superficial layer (inferior fascia) of the urogenital diaphragm?\", # 290\n",
    "        \"Where does the Extensor digitorum longus muscle originate, and what structures are located between it and the Tibialis anterior?\", # 322\n",
    "        \"What is the Peronæus tertius, and where is it inserted?\", # 322\n",
    "\n",
    "        ############## 5_Angiology.md\n",
    "        \"What are the main characteristics of the middle coat (tunica media) of arteries, and how does its composition vary with vessel size?\", # 334\n",
    "        \"Describe the composition and variations of the external coat (tunica adventitia) in arteries.\", # 334\n",
    "        \"How do the Vitelline Veins develop into parts of the portal and hepatic veins?\", # 345\n",
    "        \"What happens to the Umbilical Veins during embryonic development and after birth?\", # 345\n",
    "        \"What are the three phases of a cardiac cycle and what happens during each?\", # 358\n",
    "        \"What are the main peculiarities observed in the fetal heart's vascular system?\" # 359\n",
    "    ]   \n",
    "    import time\n",
    "    today = datetime.now()\n",
    "    folder_name = f\"{today.month}월{today.day}일\"\n",
    "    output_dir = os.path.join(\"./result\", \"knowledge_graph\", folder_name, \"subgraph_search\")\n",
    "    total_time = 0\n",
    "    for i, q in enumerate(questions):\n",
    "        print(f\"질문: {q}\")\n",
    "        start_time = time.time()\n",
    "        response, context = qa_system.generate_response(q)\n",
    "        end_time = time.time()\n",
    "        elapse_time = end_time - start_time\n",
    "        total_time += elapse_time\n",
    "        print(\"=\" * 30)\n",
    "        print(f\"답변: {response}\\n\\n\\n\")\n",
    "        print(\"=\" * 30)\n",
    "        save_results_to_file(q, response, context, output_dir, i + 1)\n",
    "    avg_time = total_time / len(questions)\n",
    "    print(\"평균 답변 시간 : %.2f\" % avg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dc484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sangwon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
